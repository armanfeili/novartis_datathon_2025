{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Add src to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from src modules\n",
    "from config import *\n",
    "from data_loader import load_all_data, merge_datasets\n",
    "from bucket_calculator import compute_avg_j, create_auxiliary_file, compute_normalized_volume\n",
    "from eda_analysis import (\n",
    "    analyze_data_quality, analyze_bucket_distribution, \n",
    "    analyze_erosion_curves, run_full_eda\n",
    ")\n",
    "\n",
    "print(\"âœ… Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391a363",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "volume, generics, medicine = load_all_data(train=True)\n",
    "merged = merge_datasets(volume, generics, medicine)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Summary:\")\n",
    "print(f\"   Total rows: {len(merged):,}\")\n",
    "print(f\"   Unique brands: {merged[['country', 'brand_name']].drop_duplicates().shape[0]}\")\n",
    "print(f\"   Columns: {merged.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create auxiliary file with buckets\n",
    "aux_df = create_auxiliary_file(merged, save=False)\n",
    "avg_j = aux_df[['country', 'brand_name', 'avg_vol']].copy()\n",
    "\n",
    "# Add normalized volume\n",
    "merged_norm = compute_normalized_volume(merged, avg_j)\n",
    "\n",
    "print(f\"\\nðŸ“Š Auxiliary file created\")\n",
    "print(f\"   Bucket distribution:\")\n",
    "print(aux_df['bucket'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f032f5",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data quality analysis\n",
    "quality_results = analyze_data_quality(merged)\n",
    "\n",
    "# Display missing values\n",
    "if quality_results['missing_values'].sum() > 0:\n",
    "    print(\"âš ï¸ Missing values found:\")\n",
    "    print(quality_results['missing_values'][quality_results['missing_values'] > 0])\n",
    "else:\n",
    "    print(\"âœ… No missing values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize volume distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Raw volume distribution\n",
    "axes[0].hist(merged['volume'], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Volume')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Volume Distribution (Raw)')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Log volume distribution\n",
    "log_volume = np.log1p(merged['volume'])\n",
    "axes[1].hist(log_volume, bins=50, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('Log(Volume + 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Volume Distribution (Log Scale)')\n",
    "\n",
    "# Normalized volume distribution\n",
    "valid_norm = merged_norm['vol_norm'].dropna()\n",
    "valid_norm = valid_norm[valid_norm < 5]  # Clip outliers for visualization\n",
    "axes[2].hist(valid_norm, bins=50, alpha=0.7, color='seagreen', edgecolor='black')\n",
    "axes[2].set_xlabel('Normalized Volume (vol/avg_j)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Normalized Volume Distribution')\n",
    "axes[2].axvline(x=1, color='red', linestyle='--', label='Pre-entry average')\n",
    "axes[2].axvline(x=0.25, color='orange', linestyle='--', label='Bucket 1 threshold')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'volume_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved to {FIGURES_DIR / 'volume_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1cacb",
   "metadata": {},
   "source": [
    "## 3. Bucket Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket distribution analysis\n",
    "bucket_results = analyze_bucket_distribution(aux_df)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Pie chart of bucket distribution\n",
    "bucket_counts = aux_df['bucket'].value_counts().sort_index()\n",
    "colors = ['#ff6b6b', '#4ecdc4']\n",
    "axes[0].pie(bucket_counts, labels=[f'Bucket {i}\\n({c} brands)' for i, c in bucket_counts.items()],\n",
    "           autopct='%1.1f%%', colors=colors, explode=[0.05, 0],\n",
    "           shadow=True, startangle=90)\n",
    "axes[0].set_title('Bucket Distribution\\n(Bucket 1 = High Erosion, 2Ã— Weight)', fontsize=12)\n",
    "\n",
    "# Mean erosion by bucket\n",
    "erosion_by_bucket = aux_df.groupby('bucket')['mean_erosion'].agg(['mean', 'std', 'count'])\n",
    "bars = axes[1].bar(erosion_by_bucket.index, erosion_by_bucket['mean'], \n",
    "                   yerr=erosion_by_bucket['std'], capsize=5, color=colors, edgecolor='black')\n",
    "axes[1].axhline(y=0.25, color='red', linestyle='--', label='Bucket 1 threshold (0.25)')\n",
    "axes[1].set_xlabel('Bucket')\n",
    "axes[1].set_ylabel('Mean Erosion (Normalized Volume)')\n",
    "axes[1].set_title('Mean Erosion by Bucket', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].set_xticks([1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'bucket_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved to {FIGURES_DIR / 'bucket_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean erosion histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot histogram\n",
    "ax.hist(aux_df['mean_erosion'].dropna(), bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax.axvline(x=0.25, color='red', linestyle='--', linewidth=2, label='Bucket 1 threshold (â‰¤0.25)')\n",
    "ax.axvline(x=aux_df['mean_erosion'].median(), color='green', linestyle=':', linewidth=2, \n",
    "           label=f'Median: {aux_df[\"mean_erosion\"].median():.3f}')\n",
    "\n",
    "ax.set_xlabel('Mean Erosion (24-month average normalized volume)', fontsize=11)\n",
    "ax.set_ylabel('Number of Brands', fontsize=11)\n",
    "ax.set_title('Distribution of Mean Erosion Across All Brands', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# Add annotation\n",
    "bucket1_count = (aux_df['mean_erosion'] <= 0.25).sum()\n",
    "ax.annotate(f'Bucket 1: {bucket1_count} brands\\n(High erosion, 2Ã— weight)', \n",
    "            xy=(0.15, ax.get_ylim()[1]*0.8), fontsize=10, \n",
    "            bbox=dict(boxstyle='round', facecolor='#ff6b6b', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'mean_erosion_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bea48e",
   "metadata": {},
   "source": [
    "## 4. Generic Erosion Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze erosion curves\n",
    "erosion_results = analyze_erosion_curves(merged_norm, aux_df)\n",
    "\n",
    "print(\"ðŸ“Š Erosion Curve Statistics:\")\n",
    "print(erosion_results['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbfec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot erosion curves by bucket\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Get post-entry data\n",
    "post_entry = merged_norm[(merged_norm['months_postgx'] >= 0) & (merged_norm['months_postgx'] <= 23)].copy()\n",
    "post_entry = post_entry.merge(aux_df[['country', 'brand_name', 'bucket']], on=['country', 'brand_name'])\n",
    "\n",
    "# Average erosion curve by month and bucket\n",
    "erosion_by_month = post_entry.groupby(['bucket', 'months_postgx'])['vol_norm'].mean().reset_index()\n",
    "\n",
    "for bucket in [1, 2]:\n",
    "    bucket_data = erosion_by_month[erosion_by_month['bucket'] == bucket]\n",
    "    color = '#ff6b6b' if bucket == 1 else '#4ecdc4'\n",
    "    label = f'Bucket {bucket} (High Erosion)' if bucket == 1 else f'Bucket {bucket} (Lower Erosion)'\n",
    "    axes[0].plot(bucket_data['months_postgx'], bucket_data['vol_norm'], \n",
    "                 marker='o', linewidth=2, color=color, label=label)\n",
    "\n",
    "axes[0].axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='Pre-entry average')\n",
    "axes[0].axhline(y=0.25, color='red', linestyle=':', alpha=0.5, label='Bucket 1 threshold')\n",
    "axes[0].set_xlabel('Months Post Generic Entry', fontsize=11)\n",
    "axes[0].set_ylabel('Normalized Volume (vol/avg_j)', fontsize=11)\n",
    "axes[0].set_title('Average Erosion Curves by Bucket', fontsize=12)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_xlim(-1, 24)\n",
    "axes[0].set_ylim(0, 1.2)\n",
    "\n",
    "# Sample individual curves\n",
    "sample_brands = aux_df.sample(min(20, len(aux_df)))[['country', 'brand_name', 'bucket']]\n",
    "sample_data = post_entry.merge(sample_brands, on=['country', 'brand_name', 'bucket'])\n",
    "\n",
    "for (country, brand), group in sample_data.groupby(['country', 'brand_name']):\n",
    "    bucket = group['bucket'].iloc[0]\n",
    "    color = '#ff6b6b' if bucket == 1 else '#4ecdc4'\n",
    "    alpha = 0.7 if bucket == 1 else 0.3\n",
    "    axes[1].plot(group['months_postgx'], group['vol_norm'], alpha=alpha, color=color, linewidth=0.8)\n",
    "\n",
    "axes[1].axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Months Post Generic Entry', fontsize=11)\n",
    "axes[1].set_ylabel('Normalized Volume', fontsize=11)\n",
    "axes[1].set_title('Sample Individual Erosion Curves (Red=Bucket1, Teal=Bucket2)', fontsize=12)\n",
    "axes[1].set_xlim(-1, 24)\n",
    "axes[1].set_ylim(0, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'erosion_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved to {FIGURES_DIR / 'erosion_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a6329",
   "metadata": {},
   "source": [
    "## 5. Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fa618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by therapeutic area\n",
    "ther_analysis = merged.groupby('ther_area').agg({\n",
    "    'volume': ['mean', 'std', 'count'],\n",
    "    'brand_name': 'nunique'\n",
    "}).round(2)\n",
    "ther_analysis.columns = ['mean_volume', 'std_volume', 'n_records', 'n_brands']\n",
    "ther_analysis = ther_analysis.sort_values('n_brands', ascending=False)\n",
    "\n",
    "print(\"ðŸ“Š Analysis by Therapeutic Area:\")\n",
    "print(ther_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d06909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize therapeutic area distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Top 10 therapeutic areas by brand count\n",
    "top_ther = ther_analysis.head(10)\n",
    "axes[0].barh(range(len(top_ther)), top_ther['n_brands'], color='steelblue', edgecolor='black')\n",
    "axes[0].set_yticks(range(len(top_ther)))\n",
    "axes[0].set_yticklabels(top_ther.index)\n",
    "axes[0].set_xlabel('Number of Brands')\n",
    "axes[0].set_title('Top 10 Therapeutic Areas by Brand Count')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Country distribution\n",
    "country_counts = merged[['country', 'brand_name']].drop_duplicates()['country'].value_counts()\n",
    "axes[1].bar(range(len(country_counts)), country_counts.values, color='coral', edgecolor='black')\n",
    "axes[1].set_xticks(range(len(country_counts)))\n",
    "axes[1].set_xticklabels(country_counts.index, rotation=45, ha='right')\n",
    "axes[1].set_xlabel('Country')\n",
    "axes[1].set_ylabel('Number of Brands')\n",
    "axes[1].set_title('Brand Count by Country')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'category_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fcb5aa",
   "metadata": {},
   "source": [
    "## 6. Competition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fba79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze generic competition\n",
    "competition = merged[merged['months_postgx'] >= 0].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Number of generics over time\n",
    "generics_over_time = competition.groupby('months_postgx')['num_generics'].mean()\n",
    "axes[0].plot(generics_over_time.index, generics_over_time.values, marker='o', color='purple', linewidth=2)\n",
    "axes[0].set_xlabel('Months Post Generic Entry')\n",
    "axes[0].set_ylabel('Average Number of Generic Competitors')\n",
    "axes[0].set_title('Generic Competition Growth Over Time')\n",
    "axes[0].set_xlim(-1, 24)\n",
    "\n",
    "# Correlation: num_generics vs normalized volume\n",
    "sample = competition.merge(merged_norm[['country', 'brand_name', 'months_postgx', 'vol_norm']], \n",
    "                           on=['country', 'brand_name', 'months_postgx'])\n",
    "sample = sample.dropna(subset=['vol_norm', 'num_generics'])\n",
    "sample = sample[sample['vol_norm'] < 3]  # Remove outliers\n",
    "\n",
    "axes[1].scatter(sample['num_generics'], sample['vol_norm'], alpha=0.1, s=10, color='steelblue')\n",
    "axes[1].set_xlabel('Number of Generic Competitors')\n",
    "axes[1].set_ylabel('Normalized Volume')\n",
    "axes[1].set_title('Impact of Generic Competition on Brand Volume')\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(sample['num_generics'], sample['vol_norm'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(sample['num_generics'].min(), sample['num_generics'].max(), 100)\n",
    "axes[1].plot(x_line, p(x_line), 'r--', linewidth=2, label=f'Trend (slope={z[0]:.4f})')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'competition_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71694fd2",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f682a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š EDA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Dataset Statistics:\")\n",
    "print(f\"   Total records: {len(merged):,}\")\n",
    "print(f\"   Unique country-brand pairs: {merged[['country', 'brand_name']].drop_duplicates().shape[0]:,}\")\n",
    "print(f\"   Countries: {merged['country'].nunique()}\")\n",
    "print(f\"   Therapeutic areas: {merged['ther_area'].nunique()}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Bucket Distribution:\")\n",
    "bucket_dist = aux_df['bucket'].value_counts().sort_index()\n",
    "print(f\"   Bucket 1 (High Erosion, 2Ã— weight): {bucket_dist.get(1, 0)} brands ({bucket_dist.get(1, 0)/len(aux_df)*100:.1f}%)\")\n",
    "print(f\"   Bucket 2 (Lower Erosion): {bucket_dist.get(2, 0)} brands ({bucket_dist.get(2, 0)/len(aux_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“‰ Erosion Statistics:\")\n",
    "print(f\"   Mean erosion (all brands): {aux_df['mean_erosion'].mean():.3f}\")\n",
    "print(f\"   Median erosion: {aux_df['mean_erosion'].median():.3f}\")\n",
    "print(f\"   Bucket 1 mean erosion: {aux_df[aux_df['bucket']==1]['mean_erosion'].mean():.3f}\")\n",
    "print(f\"   Bucket 2 mean erosion: {aux_df[aux_df['bucket']==2]['mean_erosion'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… All figures saved to: {FIGURES_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
