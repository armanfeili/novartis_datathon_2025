{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c902ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Add src to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1877f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from src modules\n",
    "from config import *\n",
    "from data_loader import load_all_data, merge_datasets\n",
    "from bucket_calculator import compute_avg_j, create_auxiliary_file\n",
    "from feature_engineering import create_all_features, get_feature_columns\n",
    "\n",
    "print(\"âœ… Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06494b",
   "metadata": {},
   "source": [
    "## 1. Load Data and Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8882e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "volume, generics, medicine = load_all_data(train=True)\n",
    "merged = merge_datasets(volume, generics, medicine)\n",
    "\n",
    "# Create auxiliary file\n",
    "aux_df = create_auxiliary_file(merged, save=False)\n",
    "avg_j = aux_df[['country', 'brand_name', 'avg_vol']].copy()\n",
    "\n",
    "print(f\"\\nðŸ“Š Loaded {len(merged):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all features\n",
    "featured = create_all_features(merged, avg_j)\n",
    "feature_cols = get_feature_columns(featured)\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Engineering Results:\")\n",
    "print(f\"   Total columns: {len(featured.columns)}\")\n",
    "print(f\"   Feature columns: {len(feature_cols)}\")\n",
    "print(f\"\\nðŸ“‹ Feature List:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea329e",
   "metadata": {},
   "source": [
    "## 2. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58fb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features for correlation\n",
    "numeric_features = featured[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Compute correlation matrix (top 15 features)\n",
    "top_features = numeric_features[:15]\n",
    "corr_matrix = featured[top_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "            center=0, ax=ax, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Feature Correlation Matrix (Top 15 Features)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'feature_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"âœ… Saved to {FIGURES_DIR / 'feature_correlation.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target (volume)\n",
    "target_corr = featured[numeric_features + ['volume']].corr()['volume'].drop('volume').sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = ['green' if x > 0 else 'red' for x in target_corr.head(20).values]\n",
    "target_corr.head(20).plot(kind='barh', ax=ax, color=colors, edgecolor='black')\n",
    "ax.set_xlabel('Correlation with Volume')\n",
    "ax.set_title('Top 20 Features by Correlation with Target (Volume)', fontsize=12)\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'feature_target_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf990394",
   "metadata": {},
   "source": [
    "## 3. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for key features\n",
    "key_features = ['months_postgx', 'volume_lag_1', 'volume_rolling_mean_3', \n",
    "                'num_generics', 'months_with_generics', 'avg_vol',\n",
    "                'volume_rolling_std_3', 'volume_lag_6', 'hospital_rate']\n",
    "\n",
    "# Filter to existing features\n",
    "key_features = [f for f in key_features if f in featured.columns]\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_features[:9]):\n",
    "    data = featured[col].dropna()\n",
    "    if len(data) > 0:\n",
    "        # Clip outliers for better visualization\n",
    "        q99 = data.quantile(0.99)\n",
    "        data_clipped = data[data <= q99]\n",
    "        \n",
    "        axes[idx].hist(data_clipped, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        axes[idx].set_title(f'{col}', fontsize=11)\n",
    "        axes[idx].set_xlabel('Value')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_text = f'Mean: {data.mean():.2f}\\nStd: {data.std():.2f}'\n",
    "        axes[idx].text(0.95, 0.95, stats_text, transform=axes[idx].transAxes,\n",
    "                       fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Key Feature Distributions', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9750e1",
   "metadata": {},
   "source": [
    "## 4. Lag Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a500e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze lag features\n",
    "lag_features = [c for c in feature_cols if 'lag' in c]\n",
    "print(f\"ðŸ“Š Lag Features: {lag_features}\")\n",
    "\n",
    "# Plot lag feature vs volume\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, lag_col in enumerate(lag_features[:6]):\n",
    "    sample = featured[[lag_col, 'volume']].dropna().sample(min(5000, len(featured)))\n",
    "    axes[idx].scatter(sample[lag_col], sample['volume'], alpha=0.3, s=10, color='steelblue')\n",
    "    axes[idx].set_xlabel(lag_col)\n",
    "    axes[idx].set_ylabel('Volume')\n",
    "    axes[idx].set_title(f'{lag_col} vs Volume')\n",
    "    \n",
    "    # Add correlation\n",
    "    corr = sample[lag_col].corr(sample['volume'])\n",
    "    axes[idx].text(0.05, 0.95, f'r = {corr:.3f}', transform=axes[idx].transAxes,\n",
    "                   fontsize=11, verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Lag Features vs Target Volume', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'lag_features_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12b806e",
   "metadata": {},
   "source": [
    "## 5. Rolling Statistics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28278e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rolling features\n",
    "rolling_features = [c for c in feature_cols if 'rolling' in c]\n",
    "print(f\"ðŸ“Š Rolling Features: {rolling_features}\")\n",
    "\n",
    "# Plot rolling features over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Sample a few brands for visualization\n",
    "sample_brands = featured[['country', 'brand_name']].drop_duplicates().sample(5)\n",
    "sample_data = featured.merge(sample_brands, on=['country', 'brand_name'])\n",
    "\n",
    "# Rolling mean 3\n",
    "for (country, brand), group in sample_data.groupby(['country', 'brand_name']):\n",
    "    group_sorted = group.sort_values('months_postgx')\n",
    "    axes[0, 0].plot(group_sorted['months_postgx'], group_sorted['volume_rolling_mean_3'], \n",
    "                    label=f'{brand[:10]}', alpha=0.7, linewidth=1.5)\n",
    "axes[0, 0].set_xlabel('Months Post GX')\n",
    "axes[0, 0].set_ylabel('Rolling Mean (3 months)')\n",
    "axes[0, 0].set_title('Rolling Mean (3 months) Over Time')\n",
    "axes[0, 0].legend(fontsize=8)\n",
    "\n",
    "# Rolling std 3\n",
    "for (country, brand), group in sample_data.groupby(['country', 'brand_name']):\n",
    "    group_sorted = group.sort_values('months_postgx')\n",
    "    axes[0, 1].plot(group_sorted['months_postgx'], group_sorted['volume_rolling_std_3'], \n",
    "                    alpha=0.7, linewidth=1.5)\n",
    "axes[0, 1].set_xlabel('Months Post GX')\n",
    "axes[0, 1].set_ylabel('Rolling Std (3 months)')\n",
    "axes[0, 1].set_title('Rolling Volatility (3 months) Over Time')\n",
    "\n",
    "# Rolling mean distributions by window\n",
    "mean_features = [c for c in rolling_features if 'mean' in c]\n",
    "for feat in mean_features:\n",
    "    data = featured[feat].dropna()\n",
    "    data = data[data < data.quantile(0.99)]  # Remove outliers\n",
    "    axes[1, 0].hist(data, bins=50, alpha=0.5, label=feat)\n",
    "axes[1, 0].set_xlabel('Rolling Mean Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Rolling Mean Distributions')\n",
    "axes[1, 0].legend(fontsize=8)\n",
    "\n",
    "# Rolling std distributions\n",
    "std_features = [c for c in rolling_features if 'std' in c]\n",
    "for feat in std_features:\n",
    "    data = featured[feat].dropna()\n",
    "    data = data[data < data.quantile(0.99)]\n",
    "    axes[1, 1].hist(data, bins=50, alpha=0.5, label=feat)\n",
    "axes[1, 1].set_xlabel('Rolling Std Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Rolling Std Distributions')\n",
    "axes[1, 1].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'rolling_features_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c31d3d",
   "metadata": {},
   "source": [
    "## 6. Competition Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competition features\n",
    "competition_features = ['num_generics', 'months_with_generics', 'generics_growth_rate']\n",
    "competition_features = [f for f in competition_features if f in featured.columns]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Num generics vs volume\n",
    "sample = featured[['num_generics', 'volume']].dropna().sample(min(5000, len(featured)))\n",
    "axes[0].scatter(sample['num_generics'], sample['volume'], alpha=0.2, s=10)\n",
    "axes[0].set_xlabel('Number of Generics')\n",
    "axes[0].set_ylabel('Volume')\n",
    "axes[0].set_title('Number of Generics vs Volume')\n",
    "\n",
    "# Months with generics vs volume  \n",
    "if 'months_with_generics' in featured.columns:\n",
    "    sample = featured[['months_with_generics', 'volume']].dropna().sample(min(5000, len(featured)))\n",
    "    axes[1].scatter(sample['months_with_generics'], sample['volume'], alpha=0.2, s=10, color='coral')\n",
    "    axes[1].set_xlabel('Months with Generics')\n",
    "    axes[1].set_ylabel('Volume')\n",
    "    axes[1].set_title('Months with Generics vs Volume')\n",
    "\n",
    "# Average volume by num_generics bins\n",
    "featured['generics_bin'] = pd.cut(featured['num_generics'], bins=[0, 2, 5, 10, 20, 100], labels=['1-2', '3-5', '6-10', '11-20', '20+'])\n",
    "avg_by_generics = featured.groupby('generics_bin')['volume'].mean()\n",
    "avg_by_generics.plot(kind='bar', ax=axes[2], color='seagreen', edgecolor='black')\n",
    "axes[2].set_xlabel('Number of Generic Competitors')\n",
    "axes[2].set_ylabel('Average Volume')\n",
    "axes[2].set_title('Average Volume by Generic Competition Level')\n",
    "axes[2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'competition_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36554c",
   "metadata": {},
   "source": [
    "## 7. Time Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c154bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Volume by months_postgx\n",
    "volume_by_month = featured.groupby('months_postgx')['volume'].mean()\n",
    "axes[0].plot(volume_by_month.index, volume_by_month.values, marker='o', color='steelblue', linewidth=2)\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', label='Generic Entry')\n",
    "axes[0].set_xlabel('Months Post Generic Entry')\n",
    "axes[0].set_ylabel('Average Volume')\n",
    "axes[0].set_title('Average Volume Over Time')\n",
    "axes[0].legend()\n",
    "\n",
    "# Volume by month_sin/cos (seasonality)\n",
    "if 'month_sin' in featured.columns:\n",
    "    sample = featured[['month_sin', 'month_cos', 'volume']].dropna()\n",
    "    axes[1].scatter(sample['month_sin'], sample['volume'], alpha=0.1, s=5, label='month_sin')\n",
    "    axes[1].set_xlabel('Month Sin (Seasonality)')\n",
    "    axes[1].set_ylabel('Volume')\n",
    "    axes[1].set_title('Seasonality Effect on Volume')\n",
    "\n",
    "# Post-entry month distribution\n",
    "if 'is_early_postgx' in featured.columns:\n",
    "    early_vs_late = featured.groupby('is_early_postgx')['volume'].mean()\n",
    "    labels = ['Late (6-23)', 'Early (0-5)']\n",
    "    axes[2].bar(range(len(early_vs_late)), early_vs_late.values, color=['coral', 'seagreen'], edgecolor='black')\n",
    "    axes[2].set_xticks(range(len(early_vs_late)))\n",
    "    axes[2].set_xticklabels(labels)\n",
    "    axes[2].set_ylabel('Average Volume')\n",
    "    axes[2].set_title('Average Volume: Early vs Late Post-Entry')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'time_features.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eff4421",
   "metadata": {},
   "source": [
    "## 8. Feature Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics summary\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Group features by type\n",
    "lag_count = len([c for c in feature_cols if 'lag' in c])\n",
    "rolling_count = len([c for c in feature_cols if 'rolling' in c])\n",
    "competition_count = len([c for c in feature_cols if any(x in c for x in ['generic', 'num_'])])\n",
    "time_count = len([c for c in feature_cols if any(x in c for x in ['month', 'year', 'sin', 'cos'])])\n",
    "other_count = len(feature_cols) - lag_count - rolling_count - competition_count - time_count\n",
    "\n",
    "print(f\"\\nðŸ“‹ Feature Categories:\")\n",
    "print(f\"   Lag features: {lag_count}\")\n",
    "print(f\"   Rolling features: {rolling_count}\")\n",
    "print(f\"   Competition features: {competition_count}\")\n",
    "print(f\"   Time features: {time_count}\")\n",
    "print(f\"   Other features: {other_count}\")\n",
    "print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "print(f\"   TOTAL: {len(feature_cols)} features\")\n",
    "\n",
    "# Missing value summary\n",
    "print(f\"\\nðŸ“Š Missing Values:\")\n",
    "missing = featured[feature_cols].isnull().sum()\n",
    "missing_pct = (missing / len(featured) * 100).round(1)\n",
    "missing_summary = pd.DataFrame({'missing': missing, 'pct': missing_pct})\n",
    "missing_summary = missing_summary[missing_summary['missing'] > 0].sort_values('pct', ascending=False)\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary.head(10))\n",
    "else:\n",
    "    print(\"   No missing values!\")\n",
    "\n",
    "print(f\"\\nâœ… All figures saved to: {FIGURES_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
