model_config:
  model:
    name: xgboost
    task: regression
  params:
    booster: gbtree
    colsample_bylevel: 1.0
    colsample_bynode: 1.0
    colsample_bytree: 0.8
    early_stopping_rounds: 50
    eval_metric: rmse
    gamma: 0
    learning_rate: 0.05
    max_depth: 6
    max_leaves: 0
    min_child_weight: 1
    n_estimators: 500
    n_jobs: -1
    objective: reg:squarederror
    reg_alpha: 0
    reg_lambda: 1
    seed: 42
    subsample: 0.8
    verbosity: 0
  sweep:
    axes:
    - params.max_depth
    - params.learning_rate
    enabled: true
  training:
    eval_metric: rmse
    use_early_stopping: true
    verbose_eval: 100
model_type: xgboost
scenario: 2
sweep_metadata:
  axes:
    params.learning_rate: 0.05
    params.max_depth: 6
  index: 3
  is_sweep: true
  total: 4
