{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64988215",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armanfeili/novartis_datathon_2025/blob/Arman/notebooks/colab/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ccfab9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# üîå Mount Google Drive (Run this cell FIRST!)\n",
        "# ==============================================================================\n",
        "# This cell must be run before any other cells in Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"‚úÖ Google Drive mounted at /content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d532273",
      "metadata": {
        "id": "2d532273"
      },
      "source": [
        "# üß¨ Novartis Datathon 2025 - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a **complete end-to-end pipeline** for the Novartis Datathon 2025.\n",
        "\n",
        "## ‚ö†Ô∏è First Steps (Colab Users)\n",
        "1. **Run the first cell above** to mount Google Drive\n",
        "2. Then run cells sequentially to clone the repo and set up the environment\n",
        "\n",
        "## Configuration Structure\n",
        "\n",
        "Each model has **one consolidated config file** supporting all training modes:\n",
        "\n",
        "| Config File | Model | Priority | Description |\n",
        "|-------------|-------|----------|-------------|\n",
        "| `configs/model_xgb.yaml` | XGBoost | 1 (Primary) | Best performance on official metric, GPU support |\n",
        "| `configs/model_lgbm.yaml` | LightGBM | 2 (Secondary) | Fast training, good for ensemble with XGBoost |\n",
        "| `configs/model_cat.yaml` | CatBoost | 3 (Tertiary) | Native categorical handling, ensemble diversity |\n",
        "| `configs/model_linear.yaml` | Linear | 4 | Ridge/Lasso/ElasticNet/Huber - baseline models |\n",
        "| `configs/model_nn.yaml` | Neural Network | 5 | PyTorch MLP - experimental |\n",
        "| `configs/model_hybrid.yaml` | Hybrid | 2 | Physics-based decay + ML residual learning |\n",
        "| `configs/model_arihow.yaml` | ARIHOW | 4 | ARIMA + Holt-Winters time series hybrid |\n",
        "\n",
        "Each config includes: `model`, `sweep`, `sweep_configs`, `scenario_best_params`, `validation`, `gpu`, `training`\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Sections\n",
        "\n",
        "1. **üîå Mount Drive** - Mount Google Drive (run first!)\n",
        "2. **üîß Environment Setup** - Clone repo, install dependencies\n",
        "3. **üìä Data Loading** - Load raw data and build panels\n",
        "4. **üî¨ Feature Engineering** - Build scenario-specific features  \n",
        "5. **üèãÔ∏è Model Training** - Train with GPU acceleration (multiple modes)\n",
        "6. **üîÑ Hyperparameter Sweep** - Grid search with K-fold CV, select by **official_metric**\n",
        "7. **ü§ù Ensemble** - XGBoost + LightGBM weighted ensemble\n",
        "8. **üì§ Submission** - Generate competition submission files\n",
        "\n",
        "---\n",
        "\n",
        "## Available Models\n",
        "\n",
        "| Model | Config File | GPU Support | Best For |\n",
        "|-------|-------------|-------------|----------|\n",
        "| `xgboost` | `model_xgb.yaml` | ‚úÖ Yes | Primary model, best official_metric |\n",
        "| `lightgbm` | `model_lgbm.yaml` | ‚úÖ Yes | Fast training, ensemble partner |\n",
        "| `catboost` | `model_cat.yaml` | ‚úÖ Yes | Categorical features, diversity |\n",
        "| `linear` | `model_linear.yaml` | ‚ùå No | Baseline, interpretability |\n",
        "| `nn` | `model_nn.yaml` | ‚úÖ Yes (PyTorch) | Experimental deep learning |\n",
        "| `hybrid` | `model_hybrid.yaml` | ‚úÖ Yes | Physics + ML hybrid |\n",
        "| `arihow` | `model_arihow.yaml` | ‚ùå No | Time series (ARIMA + Holt-Winters) |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Principles\n",
        "- ‚úÖ **Selection by official_metric** (PE), not RMSE\n",
        "- ‚úÖ **K-fold CV** (3-5 folds) for robust hyperparameter selection\n",
        "- ‚úÖ **XGB+LGBM ensemble** with optimized weights\n",
        "- ‚úÖ **GPU acceleration** for tree models on Colab\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7cb47e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7cb47e",
        "outputId": "19aa1c88-b017-42fa-b3f2-6e307d2ea8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted successfully\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.1 Detect Environment (Drive should already be mounted from cell above)\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect if running in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "print(f\"üñ•Ô∏è  Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Verify Drive is mounted (should have been mounted in the first cell)\n",
        "    if os.path.exists('/content/drive/MyDrive'):\n",
        "        print(\"‚úÖ Google Drive is mounted at /content/drive\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Google Drive not mounted! Please run the first cell to mount Drive.\")\n",
        "        print(\"   Run: drive.mount('/content/drive', force_remount=True)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - using local paths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd0aa8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd0aa8d",
        "outputId": "aad58a59-705d-4795-85cb-22bf0e22383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Repository exists at /content/drive/MyDrive/novartis_datathon_2025. Pulling latest changes...\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10 (delta 6), reused 10 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (10/10), 8.06 KiB | 26.00 KiB/s, done.\n",
            "From https://github.com/armanfeili/novartis_datathon_2025\n",
            " * branch            Arman      -> FETCH_HEAD\n",
            "   67c14aa..5c33709  Arman      -> origin/Arman\n",
            "HEAD is now at 5c33709 project setup - 3\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "\n",
            "üìÅ Project Path: /content/drive/MyDrive/novartis_datathon_2025\n",
            "üìÅ Data Path: /content/drive/MyDrive/novartis-datathon-2025/data\n",
            "üìÅ Artifacts Path: /content/drive/MyDrive/novartis-datathon-2025/artifacts\n",
            "üìÅ Submissions Path: /content/drive/MyDrive/novartis-datathon-2025/submissions\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.2 Clone Repository and Set Paths\n",
        "# ==============================================================================\n",
        "import os\n",
        "\n",
        "# --- Configuration (MODIFY THESE) ---\n",
        "REPO_URL = \"https://github.com/armanfeili/novartis_datathon_2025.git\"\n",
        "BRANCH = \"Arman\"  # Change to your working branch\n",
        "\n",
        "# Google Drive folder ID from your shared link\n",
        "# https://drive.google.com/drive/folders/1_qUAkFZPx1psU0Gc0tOtf2EHS25U2X4H\n",
        "DRIVE_FOLDER_ID = \"1_qUAkFZPx1psU0Gc0tOtf2EHS25U2X4H\"\n",
        "\n",
        "# Paths depend on environment\n",
        "if IN_COLAB:\n",
        "    DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "    PROJECT_PATH = \"/content/novartis_datathon_2025\"  # Clone to /content for speed\n",
        "    \n",
        "    # Data path - adjust based on your Drive structure\n",
        "    # Option 1: If data is in a specific folder on Drive\n",
        "    DATA_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/data\"\n",
        "    \n",
        "    # Option 2: If using the shared folder directly (uncomment if needed)\n",
        "    # DATA_PATH = f\"{DRIVE_BASE}/Colab Notebooks/novartis_data\"\n",
        "    \n",
        "    ARTIFACTS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/artifacts\"\n",
        "    SUBMISSIONS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/submissions\"\n",
        "else:\n",
        "    # Local paths (relative to notebook location)\n",
        "    PROJECT_PATH = str(Path.cwd().parent.parent)\n",
        "    DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
        "    ARTIFACTS_PATH = os.path.join(PROJECT_PATH, \"artifacts\")\n",
        "    SUBMISSIONS_PATH = os.path.join(PROJECT_PATH, \"submissions\")\n",
        "# --------------------------------\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone or update repository\n",
        "    if not os.path.exists(PROJECT_PATH):\n",
        "        print(f\"üì• Cloning repository...\")\n",
        "        !git clone --branch {BRANCH} {REPO_URL} {PROJECT_PATH}\n",
        "    else:\n",
        "        print(f\"üìÇ Repository exists. Pulling latest changes...\")\n",
        "        %cd {PROJECT_PATH}\n",
        "        !git fetch origin {BRANCH}\n",
        "        !git reset --hard origin/{BRANCH}\n",
        "    \n",
        "    %cd {PROJECT_PATH}\n",
        "    \n",
        "    # Check if data directory exists on Drive\n",
        "    if os.path.exists(DATA_PATH):\n",
        "        print(f\"‚úÖ Data directory found at: {DATA_PATH}\")\n",
        "        # Create symlink to Drive data\n",
        "        local_data = os.path.join(PROJECT_PATH, \"data\")\n",
        "        if os.path.islink(local_data):\n",
        "            os.unlink(local_data)\n",
        "        elif os.path.exists(local_data):\n",
        "            import shutil\n",
        "            shutil.rmtree(local_data)\n",
        "        os.symlink(DATA_PATH, local_data)\n",
        "        print(f\"üîó Linked data directory from Drive\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Data directory not found at: {DATA_PATH}\")\n",
        "        print(f\"   Please ensure your data is uploaded to Google Drive\")\n",
        "        print(f\"   Expected structure:\")\n",
        "        print(f\"   {DATA_PATH}/\")\n",
        "        print(f\"     ‚îú‚îÄ‚îÄ raw/\")\n",
        "        print(f\"     ‚îÇ   ‚îú‚îÄ‚îÄ TRAIN/\")\n",
        "        print(f\"     ‚îÇ   ‚îî‚îÄ‚îÄ TEST/\")\n",
        "        print(f\"     ‚îî‚îÄ‚îÄ processed/ (optional, for cached features)\")\n",
        "\n",
        "# Create required directories\n",
        "for path in [ARTIFACTS_PATH, SUBMISSIONS_PATH]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Print paths\n",
        "print(f\"\\nüìÅ Project: {PROJECT_PATH}\")\n",
        "print(f\"üìÅ Data: {DATA_PATH}\")\n",
        "print(f\"üìÅ Artifacts: {ARTIFACTS_PATH}\")\n",
        "print(f\"üìÅ Submissions: {SUBMISSIONS_PATH}\")\n",
        "\n",
        "# List data directory contents if it exists\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(f\"\\nüìÇ Data directory contents:\")\n",
        "    for item in os.listdir(DATA_PATH):\n",
        "        item_path = os.path.join(DATA_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  üìÅ {item}/\")\n",
        "        else:\n",
        "            print(f\"  üìÑ {item}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd7f350",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfd7f350",
        "outputId": "7ea6c438-55a0-40db-c862-e3d25e3f73c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  ‚úÖ torch\n",
            "  ‚úÖ numpy\n",
            "  ‚úÖ pandas\n",
            "  ‚úÖ lightgbm\n",
            "  ‚úÖ xgboost\n",
            "  ‚úÖ catboost\n",
            "  ‚úÖ sklearn\n",
            "  ‚úÖ yaml\n",
            "\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.3 Install Dependencies\n",
        "# ==============================================================================\n",
        "import subprocess\n",
        "\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Install from colab requirements\n",
        "!pip install -q -r env/colab_requirements.txt\n",
        "\n",
        "# For GPU support, ensure CUDA-compatible versions\n",
        "if IN_COLAB:\n",
        "    # XGBoost with GPU\n",
        "    !pip install -q xgboost --upgrade\n",
        "    \n",
        "    # LightGBM with GPU (requires OpenCL)\n",
        "    !pip install -q lightgbm --upgrade\n",
        "    \n",
        "    # CatBoost with GPU\n",
        "    !pip install -q catboost --upgrade\n",
        "    \n",
        "    # PyTorch for neural network model\n",
        "    !pip install -q torch --upgrade\n",
        "\n",
        "# Verify key packages\n",
        "import importlib\n",
        "\n",
        "packages = [\n",
        "    ('numpy', 'numpy'),\n",
        "    ('pandas', 'pandas'),\n",
        "    ('sklearn', 'scikit-learn'),\n",
        "    ('yaml', 'pyyaml'),\n",
        "    ('tqdm', 'tqdm'),\n",
        "    ('catboost', 'catboost'),\n",
        "    ('lightgbm', 'lightgbm'),\n",
        "    ('xgboost', 'xgboost'),\n",
        "    ('pyarrow', 'pyarrow'),\n",
        "    ('scipy', 'scipy'),\n",
        "    ('torch', 'pytorch'),\n",
        "    ('joblib', 'joblib'),\n",
        "]\n",
        "\n",
        "print(\"\\nüìã Package Status:\")\n",
        "for import_name, pkg_name in packages:\n",
        "    try:\n",
        "        mod = importlib.import_module(import_name)\n",
        "        version = getattr(mod, '__version__', 'installed')\n",
        "        print(f\"  ‚úÖ {pkg_name}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"  ‚ùå {pkg_name}: not installed\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"\\nüñ•Ô∏è GPU Status:\")\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  ‚úÖ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  ‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        print(f\"  ‚úÖ MPS (Apple Silicon) available\")\n",
        "    else:\n",
        "        print(\"  ‚ö†Ô∏è CUDA not available - using CPU\")\n",
        "except ImportError:\n",
        "    print(\"  ‚ö†Ô∏è PyTorch not installed\")\n",
        "\n",
        "# Check via nvidia-smi\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader 2>/dev/null || echo \"  ‚ÑπÔ∏è nvidia-smi not available\"\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a8cd44",
      "metadata": {
        "id": "00a8cd44"
      },
      "source": [
        "## 2. Import Modules and Verify Environment\n",
        "\n",
        "Import project modules and verify GPU availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63474d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63474d74",
        "outputId": "053ae606-25b3-4d85-cfc8-c460de74a61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üñ•Ô∏è  Device: cpu\n",
            "\n",
            "‚úÖ All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 2.1 Import Project Modules\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure project root is in path\n",
        "if PROJECT_PATH not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_PATH)\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Project imports\n",
        "from src.utils import (\n",
        "    load_config, set_seed, setup_logging, timer, \n",
        "    get_device, get_gpu_info, print_environment_info,\n",
        "    clear_memory, get_memory_usage, optimize_dataframe_memory\n",
        ")\n",
        "from src.data import (\n",
        "    get_panel, load_raw_data, prepare_base_panel, \n",
        "    compute_pre_entry_stats, handle_missing_values,\n",
        "    META_COLS\n",
        ")\n",
        "from src.features import (\n",
        "    get_features, make_features, split_features_target_meta,\n",
        "    get_feature_columns, SCENARIO_CONFIG\n",
        ")\n",
        "from src.train import (\n",
        "    train_scenario_model, run_cross_validation, \n",
        "    run_experiment, compute_sample_weights, split_features_target_meta\n",
        ")\n",
        "from src.evaluate import compute_metric1, compute_metric2, compute_per_series_error\n",
        "from src.inference import (\n",
        "    generate_submission, detect_test_scenarios, \n",
        "    validate_submission_format, save_submission_with_versioning\n",
        ")\n",
        "from src.models import get_model_class\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2.2 Display Environment Information\n",
        "# ==============================================================================\n",
        "print_environment_info()\n",
        "\n",
        "# ==============================================================================\n",
        "# 2.3 List Available Models\n",
        "# ==============================================================================\n",
        "print(\"\\nü§ñ Available Models:\")\n",
        "available_models = [\n",
        "    ('xgboost', 'XGBoost gradient boosting (GPU)'),\n",
        "    ('lightgbm', 'LightGBM fast gradient boosting'),\n",
        "    ('catboost', 'CatBoost with native categorical'),\n",
        "    ('linear', 'Ridge/Lasso/ElasticNet/Huber'),\n",
        "    ('nn', 'Neural Network (MLP)'),\n",
        "    ('hybrid', 'Physics + ML hybrid'),\n",
        "    ('arihow', 'ARIMA + Holt-Winters'),\n",
        "]\n",
        "for model_name, desc in available_models:\n",
        "    try:\n",
        "        _ = get_model_class(model_name)\n",
        "        print(f\"  ‚úÖ {model_name}: {desc}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è {model_name}: {desc} (may need dependencies)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "286fbdcc",
      "metadata": {
        "id": "286fbdcc"
      },
      "source": [
        "## 3. Load Configuration and Set Seed\n",
        "\n",
        "Load all configuration files and set random seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c891f807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c891f807",
        "outputId": "7d082df9-35cd-4f14-ffbb-1bf4c86214de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configurations loaded:\n",
            "  - Data config: ['drive', 'local', 'files', 'keys', 'dates', 'columns', 'validation']\n",
            "  - Features config: ['feature_groups', 'lags', 'rolling', 'diff', 'time_features', 'interactions', 'selection', 'encoding']\n",
            "  - Run config: ['experiment', 'run', 'reproducibility', 'cv', 'paths', 'output', 'metrics', 'logging', 'drive', 'hardware']\n",
            "  - Model configs: ['lightgbm', 'xgboost', 'catboost', 'linear', 'neural_network']\n",
            "\n",
            "üé≤ Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 3.1 Load Configurations\n",
        "# ==============================================================================\n",
        "data_config = load_config('configs/data.yaml')\n",
        "features_config = load_config('configs/features.yaml')\n",
        "run_config = load_config('configs/run_defaults.yaml')\n",
        "\n",
        "# Load all model configs (one file per model)\n",
        "model_configs = {}\n",
        "model_config_files = {\n",
        "    'xgboost': 'configs/model_xgb.yaml',\n",
        "    'lightgbm': 'configs/model_lgbm.yaml',\n",
        "    'catboost': 'configs/model_cat.yaml',\n",
        "    'linear': 'configs/model_linear.yaml',\n",
        "    'nn': 'configs/model_nn.yaml',\n",
        "    'hybrid': 'configs/model_hybrid.yaml',\n",
        "    'arihow': 'configs/model_arihow.yaml',\n",
        "}\n",
        "\n",
        "print(\"üìã Loading model configurations:\")\n",
        "for model_name, config_path in model_config_files.items():\n",
        "    try:\n",
        "        model_configs[model_name] = load_config(config_path)\n",
        "        sweep_configs = model_configs[model_name].get('sweep_configs', [])\n",
        "        n_configs = len(sweep_configs) if sweep_configs else 0\n",
        "        print(f\"  ‚úÖ {model_name}: {config_path} ({n_configs} sweep configs)\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è {model_name}: Could not load {config_path} - {e}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = run_config['reproducibility']['seed']\n",
        "set_seed(SEED)\n",
        "\n",
        "# Setup logging\n",
        "setup_logging(level=run_config.get('logging', {}).get('level', 'INFO'))\n",
        "\n",
        "print(f\"\\nüé≤ Random seed: {SEED}\")\n",
        "print(f\"üìÖ Scenarios: {list(run_config['scenarios'].keys())}\")\n",
        "\n",
        "# Display model priorities\n",
        "print(f\"\\nüèÜ Model Priorities:\")\n",
        "for name, cfg in model_configs.items():\n",
        "    priority = cfg.get('model', {}).get('priority', 99)\n",
        "    sweep_metric = cfg.get('sweep', {}).get('selection_metric', 'official_metric')\n",
        "    print(f\"  {priority}. {name.upper()} - selection: {sweep_metric}\")\n",
        "\n",
        "# Display scenario details\n",
        "print(f\"\\nüìÖ Scenario Configuration:\")\n",
        "for s_name, s_config in run_config['scenarios'].items():\n",
        "    print(f\"  {s_name}:\")\n",
        "    print(f\"    Forecast: months {s_config['forecast_start']} to {s_config['forecast_end']}\")\n",
        "    print(f\"    Feature cutoff: month {s_config['feature_cutoff']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafc46c9",
      "metadata": {
        "id": "dafc46c9"
      },
      "source": [
        "## 4. Load and Explore Data\n",
        "\n",
        "Load the training and test data panels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4881a89e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4881a89e",
        "outputId": "c4ae155e-a98c-439f-ecda-788964482add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Data Directories:\n",
            "  Raw: /content/drive/MyDrive/novartis-datathon-2025/data/raw (exists: True)\n",
            "  Interim: /content/drive/MyDrive/novartis-datathon-2025/data/interim (exists: True)\n",
            "  Processed: /content/drive/MyDrive/novartis-datathon-2025/data/processed (exists: True)\n",
            "\n",
            "üìÑ Available raw files (0):\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.1 Load Training Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading training data...\")\n",
        "\n",
        "try:\n",
        "    with timer(\"Load train panel\"):\n",
        "        train_panel = get_panel(split='train', config=data_config, use_cache=True)\n",
        "    \n",
        "    # Display statistics\n",
        "    n_series = train_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "    print(f\"\\nüìä Training Panel Statistics:\")\n",
        "    print(f\"  Shape: {train_panel.shape[0]:,} rows √ó {train_panel.shape[1]} columns\")\n",
        "    print(f\"  Unique series: {n_series:,}\")\n",
        "    print(f\"  Time range: {train_panel['months_postgx'].min()} to {train_panel['months_postgx'].max()}\")\n",
        "    \n",
        "    # Bucket distribution\n",
        "    if 'bucket' in train_panel.columns:\n",
        "        bucket_dist = train_panel[['country', 'brand_name', 'bucket']].drop_duplicates()['bucket'].value_counts()\n",
        "        print(f\"\\nü™£ Bucket Distribution:\")\n",
        "        for bucket, count in bucket_dist.items():\n",
        "            pct = count / n_series * 100\n",
        "            print(f\"  Bucket {bucket}: {count:,} series ({pct:.1f}%)\")\n",
        "    \n",
        "    # Memory usage\n",
        "    mem_mb = train_panel.memory_usage(deep=True).sum() / (1024**2)\n",
        "    print(f\"\\nüíæ Memory: {mem_mb:.1f} MB\")\n",
        "    \n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n‚ùå Data not found: {e}\")\n",
        "    print(\"\\nüìã Please ensure your data is in the correct location:\")\n",
        "    print(f\"   Expected: {DATA_PATH}/raw/TRAIN/\")\n",
        "    print(\"\\nüí° If using Google Colab:\")\n",
        "    print(\"   1. Upload data to Google Drive\")\n",
        "    print(\"   2. Run the 'setup_data_from_drive()' function in Section 8.2\")\n",
        "    print(\"   3. Re-run this cell\")\n",
        "    train_panel = None\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error loading data: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    train_panel = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9c8aac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "6b9c8aac",
        "outputId": "62bddad9-70b0-4010-ad25-55c5a9b7ef0a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1657483188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note: Update configs/data.yaml with your actual file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üìä Loaded {len(raw_data)} datasets:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/novartis_datathon_2025/src/data.py\u001b[0m in \u001b[0;36mload_raw_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Load Raw Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.2 Load Test Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading test data...\")\n",
        "\n",
        "try:\n",
        "    with timer(\"Load test panel\"):\n",
        "        test_panel = get_panel(split='test', config=data_config, use_cache=True)\n",
        "    \n",
        "    # Detect scenarios\n",
        "    test_scenarios = detect_test_scenarios(test_panel)\n",
        "    n_test_series = test_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "    \n",
        "    print(f\"\\nüìä Test Panel Statistics:\")\n",
        "    print(f\"  Shape: {test_panel.shape[0]:,} rows √ó {test_panel.shape[1]} columns\")\n",
        "    print(f\"  Unique series: {n_test_series:,}\")\n",
        "    print(f\"  Scenario 1 series: {len(test_scenarios[1]):,}\")\n",
        "    print(f\"  Scenario 2 series: {len(test_scenarios[2]):,}\")\n",
        "    \n",
        "    # Clear memory\n",
        "    clear_memory()\n",
        "    print(f\"\\nüßπ Memory cleared\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\n‚ùå Test data not found: {e}\")\n",
        "    print(\"   This is OK if you only want to train - test data is only needed for submission\")\n",
        "    test_panel = None\n",
        "    test_scenarios = {1: [], 2: []}\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error loading test data: {e}\")\n",
        "    test_panel = None\n",
        "    test_scenarios = {1: [], 2: []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ae59ab",
      "metadata": {
        "id": "98ae59ab"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 4.3 Quick Data Exploration\n",
        "# ==============================================================================\n",
        "if train_panel is not None:\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    # Set up plotting\n",
        "    plt.style.use('default')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. y_norm distribution\n",
        "    ax = axes[0, 0]\n",
        "    if 'y_norm' in train_panel.columns:\n",
        "        train_panel['y_norm'].hist(bins=50, ax=ax, color='steelblue', edgecolor='white')\n",
        "        ax.axvline(x=1.0, color='red', linestyle='--', label='No erosion (1.0)')\n",
        "        ax.axvline(x=0.25, color='orange', linestyle='--', label='Bucket 1 threshold')\n",
        "        ax.set_xlabel('Normalized Volume (y_norm)')\n",
        "        ax.set_ylabel('Frequency')\n",
        "        ax.set_title('Distribution of y_norm')\n",
        "        ax.legend()\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'y_norm not available', ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_title('y_norm Distribution (N/A)')\n",
        "    \n",
        "    # 2. Mean erosion curve by bucket\n",
        "    ax = axes[0, 1]\n",
        "    if 'bucket' in train_panel.columns and 'y_norm' in train_panel.columns:\n",
        "        for bucket in [1, 2]:\n",
        "            bucket_data = train_panel[train_panel['bucket'] == bucket]\n",
        "            if len(bucket_data) > 0:\n",
        "                erosion_by_month = bucket_data.groupby('months_postgx')['y_norm'].mean()\n",
        "                ax.plot(erosion_by_month.index, erosion_by_month.values, \n",
        "                        label=f'Bucket {bucket}', linewidth=2)\n",
        "        ax.axhline(y=1.0, color='gray', linestyle=':', alpha=0.7)\n",
        "        ax.set_xlabel('Months Post Generic Entry')\n",
        "        ax.set_ylabel('Mean Normalized Volume')\n",
        "        ax.set_title('Erosion Curves by Bucket')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'bucket/y_norm not available', ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_title('Erosion Curves (N/A)')\n",
        "    \n",
        "    # 3. Number of generics over time\n",
        "    ax = axes[1, 0]\n",
        "    if 'n_gxs' in train_panel.columns:\n",
        "        ngxs_by_month = train_panel.groupby('months_postgx')['n_gxs'].mean()\n",
        "        ax.bar(ngxs_by_month.index, ngxs_by_month.values, color='forestgreen', alpha=0.7)\n",
        "        ax.set_xlabel('Months Post Generic Entry')\n",
        "        ax.set_ylabel('Mean Number of Generics')\n",
        "        ax.set_title('Average Generic Competition Over Time')\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, 'n_gxs not available', ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.set_title('Generic Competition (N/A)')\n",
        "    \n",
        "    # 4. Hospital rate distribution\n",
        "    ax = axes[1, 1]\n",
        "    if 'hospital_rate' in train_panel.columns:\n",
        "        hr_by_series = train_panel.groupby(['country', 'brand_name'])['hospital_rate'].first()\n",
        "        hr_by_series.hist(bins=30, ax=ax, color='purple', edgecolor='white', alpha=0.7)\n",
        "        ax.set_xlabel('Hospital Rate (%)')\n",
        "        ax.set_ylabel('Number of Series')\n",
        "        ax.set_title('Hospital Rate Distribution')\n",
        "    else:\n",
        "        # Try alternative columns\n",
        "        if 'country' in train_panel.columns:\n",
        "            country_dist = train_panel.groupby(['country', 'brand_name']).size().reset_index()['country'].value_counts()\n",
        "            country_dist.plot(kind='bar', ax=ax, color='purple', alpha=0.7)\n",
        "            ax.set_xlabel('Country')\n",
        "            ax.set_ylabel('Number of Series')\n",
        "            ax.set_title('Series by Country')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, 'No distribution data available', ha='center', va='center', transform=ax.transAxes)\n",
        "            ax.set_title('Distribution (N/A)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Data exploration complete\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Training data not loaded - skipping exploration\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba3b589",
      "metadata": {
        "id": "eba3b589"
      },
      "source": [
        "## 5. Feature Engineering\n",
        "\n",
        "Build scenario-specific features for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96056c47",
      "metadata": {
        "id": "96056c47"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 5.1 Build Features for Both Scenarios\n",
        "# ==============================================================================\n",
        "\n",
        "if train_panel is None:\n",
        "    print(\"‚ùå Training data not loaded - cannot build features\")\n",
        "    print(\"   Please fix data loading issues first (Section 4)\")\n",
        "else:\n",
        "    # Build Scenario 1 features (forecast months 0-23 using pre-entry only)\n",
        "    print(\"üî¨ Building Scenario 1 features...\")\n",
        "    try:\n",
        "        with timer(\"Scenario 1 features\"):\n",
        "            panel_s1 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "            panel_features_s1 = make_features(panel_s1, scenario=1, mode='train', config=features_config)\n",
        "        \n",
        "        n_features_s1 = len([c for c in panel_features_s1.columns if c not in META_COLS])\n",
        "        print(f\"  Panel shape: {panel_features_s1.shape}\")\n",
        "        print(f\"  Features: {n_features_s1}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error building S1 features: {e}\")\n",
        "        panel_features_s1 = None\n",
        "    \n",
        "    # Build Scenario 2 features (forecast months 6-23 using pre-entry + months 0-5)\n",
        "    print(\"\\nüî¨ Building Scenario 2 features...\")\n",
        "    try:\n",
        "        with timer(\"Scenario 2 features\"):\n",
        "            panel_s2 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "            panel_features_s2 = make_features(panel_s2, scenario=2, mode='train', config=features_config)\n",
        "        \n",
        "        n_features_s2 = len([c for c in panel_features_s2.columns if c not in META_COLS])\n",
        "        print(f\"  Panel shape: {panel_features_s2.shape}\")\n",
        "        print(f\"  Features: {n_features_s2}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error building S2 features: {e}\")\n",
        "        panel_features_s2 = None\n",
        "    \n",
        "    # Display some feature examples\n",
        "    if panel_features_s1 is not None:\n",
        "        feature_cols_s1 = [c for c in panel_features_s1.columns if c not in META_COLS]\n",
        "        print(f\"\\nüìã Sample Features (Scenario 1):\")\n",
        "        print(f\"  {feature_cols_s1[:10]}...\")\n",
        "    \n",
        "    # Check for early erosion features in S2 only\n",
        "    if panel_features_s2 is not None:\n",
        "        feature_cols_s2 = [c for c in panel_features_s2.columns if c not in META_COLS]\n",
        "        s2_only_features = [c for c in feature_cols_s2 if 'erosion_0' in c or 'early_' in c or 'month_0' in c]\n",
        "        if s2_only_features:\n",
        "            print(f\"\\nüìã Scenario 2 Specific Features (early erosion):\")\n",
        "            print(f\"  {s2_only_features[:5]}...\")\n",
        "    \n",
        "    clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22178dd4",
      "metadata": {
        "id": "22178dd4"
      },
      "source": [
        "## 6. Model Training\n",
        "\n",
        "Train CatBoost models for both scenarios using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22078bc1",
      "metadata": {
        "id": "22078bc1"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.1 Training Configuration\n",
        "# ==============================================================================\n",
        "\n",
        "# ============ CONFIGURE YOUR TRAINING HERE ============\n",
        "# Model options: 'xgboost', 'lightgbm', 'catboost', 'linear', 'nn', 'hybrid', 'arihow'\n",
        "MODEL_TYPE = 'xgboost'  # Primary model (best performing)\n",
        "\n",
        "# Training mode options:\n",
        "# - 'quick'    : Use best known params (from config scenario_best_params)\n",
        "# - 'cv'       : Train with K-fold cross-validation using best params\n",
        "# - 'sweep'    : Run hyperparameter sweep with holdout validation\n",
        "# - 'sweep_cv' : Run sweep with K-fold cross-validation (most robust)\n",
        "# - 'ensemble' : Train XGBoost + LightGBM ensemble\n",
        "# - 'compare'  : Compare all models and select best by official_metric\n",
        "TRAINING_MODE = 'cv'\n",
        "\n",
        "N_FOLDS = 5  # Number of CV folds\n",
        "USE_GPU = True  # Enable GPU acceleration (for tree models)\n",
        "# =====================================================\n",
        "\n",
        "# Create run ID\n",
        "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = Path(ARTIFACTS_PATH) / RUN_ID\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üèÉ Training Configuration:\")\n",
        "print(f\"  Run ID: {RUN_ID}\")\n",
        "print(f\"  Model: {MODEL_TYPE}\")\n",
        "print(f\"  Mode: {TRAINING_MODE}\")\n",
        "print(f\"  CV Folds: {N_FOLDS}\")\n",
        "print(f\"  Artifacts: {RUN_DIR}\")\n",
        "\n",
        "# Check GPU availability and configure\n",
        "gpu_info = get_gpu_info()\n",
        "GPU_AVAILABLE = gpu_info.get('gpu_available', False) and gpu_info.get('cuda_version')\n",
        "\n",
        "if GPU_AVAILABLE and USE_GPU:\n",
        "    print(f\"  üöÄ GPU: {gpu_info.get('device_name', 'Available')} - GPU training enabled\")\n",
        "else:\n",
        "    print(f\"  üíª Using CPU training\")\n",
        "    USE_GPU = False\n",
        "\n",
        "# Set environment variable for thread safety (important for XGBoost/LightGBM)\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "\n",
        "# Show sweep configuration if using sweep mode\n",
        "if TRAINING_MODE in ['sweep', 'sweep_cv'] and MODEL_TYPE in model_configs:\n",
        "    sweep_config = model_configs[MODEL_TYPE].get('sweep', {})\n",
        "    print(f\"\\nüîç Sweep Configuration:\")\n",
        "    print(f\"  Selection metric: {sweep_config.get('selection_metric', 'official_metric')}\")\n",
        "    \n",
        "    # Show sweep configs if available\n",
        "    sweep_configs_list = model_configs[MODEL_TYPE].get('sweep_configs', [])\n",
        "    if sweep_configs_list:\n",
        "        print(f\"  Named configurations: {len(sweep_configs_list)}\")\n",
        "        for cfg in sweep_configs_list[:5]:\n",
        "            print(f\"    - {cfg.get('id', 'unnamed')}: {cfg.get('description', 'No description')}\")\n",
        "        if len(sweep_configs_list) > 5:\n",
        "            print(f\"    ... and {len(sweep_configs_list) - 5} more\")\n",
        "    \n",
        "    # Show grid if available\n",
        "    grid = sweep_config.get('grid', {})\n",
        "    if grid:\n",
        "        total_combos = 1\n",
        "        for param, values in grid.items():\n",
        "            if isinstance(values, list):\n",
        "                print(f\"  - {param}: {values}\")\n",
        "                total_combos *= len(values)\n",
        "        print(f\"  Total grid combinations: {total_combos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417260a5",
      "metadata": {
        "id": "417260a5"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.2 Configure GPU-Enabled Model Parameters\n",
        "# ==============================================================================\n",
        "\n",
        "def get_gpu_model_config(model_type: str, base_config: dict, use_gpu: bool = True) -> dict:\n",
        "    \"\"\"\n",
        "    Get model configuration with GPU settings enabled.\n",
        "    Uses gpu section from consolidated model config files.\n",
        "    \n",
        "    Args:\n",
        "        model_type: 'xgboost', 'lightgbm', 'catboost', 'nn', etc.\n",
        "        base_config: Base model configuration dict\n",
        "        use_gpu: Whether to enable GPU\n",
        "        \n",
        "    Returns:\n",
        "        Updated model configuration\n",
        "    \"\"\"\n",
        "    import copy\n",
        "    config = copy.deepcopy(base_config)\n",
        "    \n",
        "    # Get params from config - could be in 'model.params' or 'params' directly\n",
        "    if 'model' in config and 'params' in config['model']:\n",
        "        params = config['model']['params'].copy()\n",
        "    elif 'params' in config:\n",
        "        params = config['params'].copy()\n",
        "    else:\n",
        "        params = {}\n",
        "    \n",
        "    gpu_config = config.get('gpu', {})\n",
        "    \n",
        "    if use_gpu and GPU_AVAILABLE:\n",
        "        # Apply GPU settings from config\n",
        "        if model_type in ['xgboost', 'xgb']:\n",
        "            params['tree_method'] = gpu_config.get('tree_method', 'gpu_hist')\n",
        "            params['gpu_id'] = gpu_config.get('gpu_id', 0)\n",
        "            params['predictor'] = gpu_config.get('predictor', 'gpu_predictor')\n",
        "            print(\"  üöÄ XGBoost GPU mode enabled (tree_method='gpu_hist')\")\n",
        "            \n",
        "        elif model_type in ['lightgbm', 'lgbm']:\n",
        "            params['device'] = 'gpu'\n",
        "            params['gpu_platform_id'] = gpu_config.get('gpu_platform_id', 0)\n",
        "            params['gpu_device_id'] = gpu_config.get('gpu_device_id', 0)\n",
        "            print(\"  ‚ö° LightGBM GPU mode enabled (device='gpu')\")\n",
        "            \n",
        "        elif model_type in ['catboost', 'cat']:\n",
        "            params['task_type'] = 'GPU'\n",
        "            params['devices'] = str(gpu_config.get('device_id', 0))\n",
        "            print(\"  üê± CatBoost GPU mode enabled (task_type='GPU')\")\n",
        "            \n",
        "        elif model_type in ['nn', 'neural', 'mlp']:\n",
        "            # Neural network automatically uses GPU via PyTorch\n",
        "            print(\"  üß† Neural Network will use GPU via PyTorch\")\n",
        "        else:\n",
        "            print(f\"  üíª {model_type} using CPU (no GPU config)\")\n",
        "    else:\n",
        "        # Use CPU settings\n",
        "        if model_type in ['xgboost', 'xgb']:\n",
        "            params['tree_method'] = 'hist'\n",
        "        elif model_type in ['lightgbm', 'lgbm']:\n",
        "            params['device'] = 'cpu'\n",
        "        elif model_type in ['catboost', 'cat']:\n",
        "            params['task_type'] = 'CPU'\n",
        "        print(f\"  üíª {model_type} CPU mode\")\n",
        "    \n",
        "    # Update config with modified params\n",
        "    if 'model' in config:\n",
        "        config['model']['params'] = params\n",
        "    else:\n",
        "        config['params'] = params\n",
        "    \n",
        "    return config\n",
        "\n",
        "# Get GPU-enabled config for selected model\n",
        "print(f\"\\nüîß Configuring {MODEL_TYPE}...\")\n",
        "\n",
        "if MODEL_TYPE in model_configs:\n",
        "    current_model_config = get_gpu_model_config(MODEL_TYPE, model_configs[MODEL_TYPE], USE_GPU)\n",
        "else:\n",
        "    print(f\"  ‚ö†Ô∏è No config found for {MODEL_TYPE}, using empty config\")\n",
        "    current_model_config = {}\n",
        "\n",
        "# Get model class\n",
        "try:\n",
        "    ModelClass = get_model_class(MODEL_TYPE)\n",
        "    print(f\"  Model class: {ModelClass.__name__}\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ùå Could not load model class: {e}\")\n",
        "    ModelClass = None\n",
        "\n",
        "# Display selected params\n",
        "if 'model' in current_model_config and 'params' in current_model_config['model']:\n",
        "    selected_params = current_model_config['model']['params']\n",
        "elif 'params' in current_model_config:\n",
        "    selected_params = current_model_config['params']\n",
        "else:\n",
        "    selected_params = {}\n",
        "\n",
        "if selected_params:\n",
        "    print(f\"\\nüìã Model Parameters:\")\n",
        "    for k, v in list(selected_params.items())[:10]:\n",
        "        print(f\"  {k}: {v}\")\n",
        "    if len(selected_params) > 10:\n",
        "        print(f\"  ... and {len(selected_params) - 10} more\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddfd0994",
      "metadata": {
        "id": "ddfd0994"
      },
      "source": [
        "### 6.3 Train Scenario 1 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b7bf71",
      "metadata": {
        "id": "d6b7bf71"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.3 Train Scenario 1 Model\n",
        "# ==============================================================================\n",
        "print(f\"üèãÔ∏è Training Scenario 1 - {MODEL_TYPE.upper()}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Build features for Scenario 1\n",
        "print(\"Building Scenario 1 features...\")\n",
        "with timer(\"Feature engineering S1\"):\n",
        "    panel_s1 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "    panel_features_s1 = make_features(panel_s1, scenario=1, mode='train', config=features_config)\n",
        "\n",
        "# Run cross-validation\n",
        "models_s1, s1_cv_results, oof_s1 = run_cross_validation(\n",
        "    panel_features=panel_features_s1,\n",
        "    scenario=1,\n",
        "    model_type=MODEL_TYPE,\n",
        "    model_config=current_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_oof=True,\n",
        "    artifacts_dir=RUN_DIR / 'models_s1',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 1 Training Complete\")\n",
        "print(f\"  Mean CV Official Metric: {s1_cv_results['cv_official_mean']:.6f} ¬± {s1_cv_results['cv_official_std']:.6f}\")\n",
        "print(f\"  Mean CV RMSE: {s1_cv_results['cv_rmse_mean']:.6f} ¬± {s1_cv_results['cv_rmse_std']:.6f}\")\n",
        "\n",
        "# Save S1 OOF predictions\n",
        "if len(oof_s1) > 0:\n",
        "    oof_s1.to_csv(RUN_DIR / 'oof_s1.csv', index=False)\n",
        "    print(f\"  OOF predictions saved: {len(oof_s1)} rows\")\n",
        "\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b361db6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.4 Train Scenario 2 Model\n",
        "# ==============================================================================\n",
        "print(f\"üèãÔ∏è Training Scenario 2 - {MODEL_TYPE.upper()}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Build features for Scenario 2\n",
        "print(\"Building Scenario 2 features...\")\n",
        "with timer(\"Feature engineering S2\"):\n",
        "    panel_s2 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "    panel_features_s2 = make_features(panel_s2, scenario=2, mode='train', config=features_config)\n",
        "\n",
        "# Run cross-validation\n",
        "models_s2, s2_cv_results, oof_s2 = run_cross_validation(\n",
        "    panel_features=panel_features_s2,\n",
        "    scenario=2,\n",
        "    model_type=MODEL_TYPE,\n",
        "    model_config=current_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_oof=True,\n",
        "    artifacts_dir=RUN_DIR / 'models_s2',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 2 Training Complete\")\n",
        "print(f\"  Mean CV Official Metric: {s2_cv_results['cv_official_mean']:.6f} ¬± {s2_cv_results['cv_official_std']:.6f}\")\n",
        "print(f\"  Mean CV RMSE: {s2_cv_results['cv_rmse_mean']:.6f} ¬± {s2_cv_results['cv_rmse_std']:.6f}\")\n",
        "\n",
        "# Save S2 OOF predictions\n",
        "if len(oof_s2) > 0:\n",
        "    oof_s2.to_csv(RUN_DIR / 'oof_s2.csv', index=False)\n",
        "    print(f\"  OOF predictions saved: {len(oof_s2)} rows\")\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Model: {MODEL_TYPE.upper()}\")\n",
        "print(f\"  GPU: {'Enabled' if USE_GPU and GPU_AVAILABLE else 'Disabled'}\")\n",
        "print(f\"  Scenario 1 CV: {s1_cv_results['cv_official_mean']:.6f} ¬± {s1_cv_results['cv_official_std']:.6f}\")\n",
        "print(f\"  Scenario 2 CV: {s2_cv_results['cv_official_mean']:.6f} ¬± {s2_cv_results['cv_official_std']:.6f}\")\n",
        "print(f\"  Models saved to: {RUN_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912dfd34",
      "metadata": {},
      "source": [
        "## 6.5 Advanced Training Options\n",
        "\n",
        "The cells below provide advanced training options:\n",
        "- **Hyperparameter Sweep**: Grid search with K-fold CV to find optimal parameters\n",
        "- **Multi-Model Training**: Train all models (XGBoost, LightGBM, CatBoost)\n",
        "- **Ensemble**: Combine XGBoost + LightGBM predictions for better performance\n",
        "\n",
        "‚ö†Ô∏è These are optional and computationally intensive. Skip to Section 7 for basic submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4b9b11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5a Train All Models (Compare Performance)\n",
        "# ==============================================================================\n",
        "# Set RUN_ALL_MODELS = True to train all three models and compare\n",
        "\n",
        "RUN_ALL_MODELS = False  # ‚ö†Ô∏è Set to True to run (takes ~15-30 min with GPU)\n",
        "\n",
        "if RUN_ALL_MODELS:\n",
        "    all_model_results = {}\n",
        "    \n",
        "    # Models to compare (tree-based models with GPU support)\n",
        "    models_to_compare = ['xgboost', 'lightgbm', 'catboost']\n",
        "    \n",
        "    for model_name in models_to_compare:\n",
        "        if model_name not in model_configs:\n",
        "            print(f\"‚ö†Ô∏è Config not found for {model_name}, skipping\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üèãÔ∏è Training {model_name.upper()}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Get GPU-enabled config\n",
        "        model_cfg = get_gpu_model_config(model_name, model_configs[model_name], USE_GPU)\n",
        "        \n",
        "        # Train S1\n",
        "        panel_s1 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "        panel_features_s1 = make_features(panel_s1, scenario=1, mode='train', config=features_config)\n",
        "        \n",
        "        s1_models, s1_results, _ = run_cross_validation(\n",
        "            panel_features=panel_features_s1,\n",
        "            scenario=1,\n",
        "            model_type=model_name,\n",
        "            model_config=model_cfg,\n",
        "            run_config=run_config,\n",
        "            n_folds=N_FOLDS,\n",
        "            artifacts_dir=RUN_DIR / f'{model_name}_s1',\n",
        "            run_id=RUN_ID\n",
        "        )\n",
        "        \n",
        "        # Train S2\n",
        "        panel_s2 = get_panel(split='train', config=data_config, use_cache=True)\n",
        "        panel_features_s2 = make_features(panel_s2, scenario=2, mode='train', config=features_config)\n",
        "        \n",
        "        s2_models, s2_results, _ = run_cross_validation(\n",
        "            panel_features=panel_features_s2,\n",
        "            scenario=2,\n",
        "            model_type=model_name,\n",
        "            model_config=model_cfg,\n",
        "            run_config=run_config,\n",
        "            n_folds=N_FOLDS,\n",
        "            artifacts_dir=RUN_DIR / f'{model_name}_s2',\n",
        "            run_id=RUN_ID\n",
        "        )\n",
        "        \n",
        "        all_model_results[model_name] = {\n",
        "            's1_mean': s1_results['cv_official_mean'],\n",
        "            's1_std': s1_results['cv_official_std'],\n",
        "            's2_mean': s2_results['cv_official_mean'],\n",
        "            's2_std': s2_results['cv_official_std'],\n",
        "        }\n",
        "        \n",
        "        print(f\"  S1: {s1_results['cv_official_mean']:.4f} ¬± {s1_results['cv_official_std']:.4f}\")\n",
        "        print(f\"  S2: {s2_results['cv_official_mean']:.4f} ¬± {s2_results['cv_official_std']:.4f}\")\n",
        "        \n",
        "        clear_memory()\n",
        "    \n",
        "    # Display comparison table\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä MODEL COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    comparison_df = pd.DataFrame([\n",
        "        {\n",
        "            'Model': name.upper(),\n",
        "            'S1 Mean': f\"{r['s1_mean']:.4f}\",\n",
        "            'S1 Std': f\"¬±{r['s1_std']:.4f}\",\n",
        "            'S2 Mean': f\"{r['s2_mean']:.4f}\",\n",
        "            'S2 Std': f\"¬±{r['s2_std']:.4f}\",\n",
        "        }\n",
        "        for name, r in all_model_results.items()\n",
        "    ])\n",
        "    display(comparison_df)\n",
        "    \n",
        "    # Find best model\n",
        "    best_model = min(all_model_results.keys(), \n",
        "                     key=lambda m: all_model_results[m]['s1_mean'] + all_model_results[m]['s2_mean'])\n",
        "    print(f\"\\nüèÜ Best overall model: {best_model.upper()}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_ALL_MODELS = True to train and compare all models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3fe3c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5b Hyperparameter Sweep with K-Fold CV (using consolidated configs)\n",
        "# ==============================================================================\n",
        "# Run a grid search over hyperparameters with cross-validation\n",
        "# Sweep parameters are defined in configs/model_*.yaml files\n",
        "\n",
        "RUN_SWEEP = False  # ‚ö†Ô∏è Set to True to run (takes ~30-60 min)\n",
        "\n",
        "if RUN_SWEEP:\n",
        "    from src.config_sweep import generate_sweep_runs, get_config_by_id\n",
        "    \n",
        "    # Select model for sweep (use consolidated config files)\n",
        "    SWEEP_MODEL = 'xgboost'  # 'xgboost', 'lightgbm', 'catboost'\n",
        "    SWEEP_FOLDS = 3  # Fewer folds for faster sweep\n",
        "    \n",
        "    if SWEEP_MODEL not in model_configs:\n",
        "        print(f\"‚ùå Config not found for {SWEEP_MODEL}\")\n",
        "    else:\n",
        "        # Get sweep configuration from consolidated model config\n",
        "        sweep_model_config = model_configs[SWEEP_MODEL]\n",
        "        sweep_config = sweep_model_config.get('sweep', {})\n",
        "        sweep_configs_list = sweep_model_config.get('sweep_configs', [])\n",
        "        selection_metric = sweep_config.get('selection_metric', 'official_metric')\n",
        "        \n",
        "        print(f\"üîç Running {SWEEP_MODEL.upper()} hyperparameter sweep...\")\n",
        "        print(f\"  Config file: configs/model_{SWEEP_MODEL.replace('boost', '')}.yaml\")\n",
        "        print(f\"  Selection metric: {selection_metric}\")\n",
        "        print(f\"  Folds: {SWEEP_FOLDS}\")\n",
        "        print(f\"  GPU: {'Enabled' if USE_GPU else 'Disabled'}\")\n",
        "        \n",
        "        if sweep_configs_list:\n",
        "            print(f\"\\n  Named configurations to sweep: {len(sweep_configs_list)}\")\n",
        "            for cfg in sweep_configs_list:\n",
        "                print(f\"    - {cfg.get('id', 'unnamed')}: {cfg.get('description', '')}\")\n",
        "        \n",
        "        # Run sweep for both scenarios\n",
        "        sweep_all_results = {}\n",
        "        \n",
        "        for scenario in [1, 2]:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Scenario {scenario} Sweep\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            # Build features for this scenario\n",
        "            panel = get_panel(split='train', config=data_config, use_cache=True)\n",
        "            panel_features = make_features(panel, scenario=scenario, mode='train', config=features_config)\n",
        "            \n",
        "            config_results = []\n",
        "            \n",
        "            for cfg in sweep_configs_list:\n",
        "                config_id = cfg.get('id', 'default')\n",
        "                config_params = cfg.get('params', {})\n",
        "                \n",
        "                print(f\"\\n  Testing config: {config_id}\")\n",
        "                \n",
        "                # Merge params with base config\n",
        "                test_config = get_gpu_model_config(SWEEP_MODEL, sweep_model_config, USE_GPU)\n",
        "                if 'model' in test_config and 'params' in test_config['model']:\n",
        "                    test_config['model']['params'].update(config_params)\n",
        "                elif 'params' in test_config:\n",
        "                    test_config['params'].update(config_params)\n",
        "                \n",
        "                # Run CV for this config\n",
        "                _, cv_results, _ = run_cross_validation(\n",
        "                    panel_features=panel_features,\n",
        "                    scenario=scenario,\n",
        "                    model_type=SWEEP_MODEL,\n",
        "                    model_config=test_config,\n",
        "                    run_config=run_config,\n",
        "                    n_folds=SWEEP_FOLDS,\n",
        "                    save_oof=False,\n",
        "                )\n",
        "                \n",
        "                config_results.append({\n",
        "                    'config_id': config_id,\n",
        "                    'official_mean': cv_results['cv_official_mean'],\n",
        "                    'official_std': cv_results['cv_official_std'],\n",
        "                    'rmse_mean': cv_results['cv_rmse_mean'],\n",
        "                })\n",
        "                \n",
        "                print(f\"    {selection_metric}: {cv_results['cv_official_mean']:.4f} ¬± {cv_results['cv_official_std']:.4f}\")\n",
        "            \n",
        "            # Find best config\n",
        "            if selection_metric == 'official_metric':\n",
        "                best_config = min(config_results, key=lambda x: x['official_mean'])\n",
        "            else:\n",
        "                best_config = min(config_results, key=lambda x: x['rmse_mean'])\n",
        "            \n",
        "            sweep_all_results[scenario] = {\n",
        "                'best_config': best_config['config_id'],\n",
        "                'best_mean_metric': best_config['official_mean'],\n",
        "                'best_std_metric': best_config['official_std'],\n",
        "                'all_results': config_results,\n",
        "            }\n",
        "            \n",
        "            print(f\"\\n‚úÖ Best config: {best_config['config_id']}\")\n",
        "            print(f\"   Mean {selection_metric}: {best_config['official_mean']:.4f} ¬± {best_config['official_std']:.4f}\")\n",
        "            \n",
        "            clear_memory()\n",
        "        \n",
        "        # Summary\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"üìä SWEEP SUMMARY ({SWEEP_MODEL.upper()})\")\n",
        "        print(\"=\"*60)\n",
        "        for s in [1, 2]:\n",
        "            r = sweep_all_results[s]\n",
        "            print(f\"  Scenario {s}: {r['best_mean_metric']:.4f}\")\n",
        "            print(f\"    Best config: {r['best_config']}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_SWEEP = True to run hyperparameter sweep\")\n",
        "    print(\"   Sweep configuration is in configs/model_*.yaml files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e12de8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5c XGBoost + LightGBM Ensemble\n",
        "# ==============================================================================\n",
        "# Train both XGBoost and LightGBM and combine predictions\n",
        "# Ensemble settings are defined in configs/model_xgb.yaml and configs/model_lgbm.yaml\n",
        "\n",
        "RUN_ENSEMBLE = False  # ‚ö†Ô∏è Set to True to run (takes ~10-20 min)\n",
        "\n",
        "if RUN_ENSEMBLE:\n",
        "    print(\"ü§ù Training XGBoost + LightGBM Ensemble...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    ensemble_results = {}\n",
        "    \n",
        "    for scenario in [1, 2]:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Scenario {scenario} Ensemble\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Build features\n",
        "        panel = get_panel(split='train', config=data_config, use_cache=True)\n",
        "        panel_features = make_features(panel, scenario=scenario, mode='train', config=features_config)\n",
        "        \n",
        "        # Train XGBoost\n",
        "        print(\"\\n  Training XGBoost...\")\n",
        "        xgb_cfg = get_gpu_model_config('xgboost', model_configs['xgboost'], USE_GPU)\n",
        "        xgb_models, xgb_results, xgb_oof = run_cross_validation(\n",
        "            panel_features=panel_features,\n",
        "            scenario=scenario,\n",
        "            model_type='xgboost',\n",
        "            model_config=xgb_cfg,\n",
        "            run_config=run_config,\n",
        "            n_folds=N_FOLDS,\n",
        "            save_oof=True,\n",
        "            artifacts_dir=RUN_DIR / f'ensemble_xgb_s{scenario}',\n",
        "        )\n",
        "        \n",
        "        # Train LightGBM\n",
        "        print(\"\\n  Training LightGBM...\")\n",
        "        lgbm_cfg = get_gpu_model_config('lightgbm', model_configs['lightgbm'], USE_GPU)\n",
        "        lgbm_models, lgbm_results, lgbm_oof = run_cross_validation(\n",
        "            panel_features=panel_features,\n",
        "            scenario=scenario,\n",
        "            model_type='lightgbm',\n",
        "            model_config=lgbm_cfg,\n",
        "            run_config=run_config,\n",
        "            n_folds=N_FOLDS,\n",
        "            save_oof=True,\n",
        "            artifacts_dir=RUN_DIR / f'ensemble_lgbm_s{scenario}',\n",
        "        )\n",
        "        \n",
        "        # Optimize ensemble weights using OOF predictions\n",
        "        print(\"\\n  Optimizing ensemble weights...\")\n",
        "        from src.models.ensemble import EnsembleBlender\n",
        "        \n",
        "        # Align OOF predictions\n",
        "        oof_merged = xgb_oof.merge(\n",
        "            lgbm_oof[['country', 'brand_name', 'months_postgx', 'y_pred']],\n",
        "            on=['country', 'brand_name', 'months_postgx'],\n",
        "            suffixes=('_xgb', '_lgbm')\n",
        "        )\n",
        "        \n",
        "        if 'y_pred_xgb' not in oof_merged.columns:\n",
        "            oof_merged['y_pred_xgb'] = oof_merged['y_pred']\n",
        "        \n",
        "        # Fit blender\n",
        "        blender = EnsembleBlender(constrain_weights=True)\n",
        "        blender.fit(\n",
        "            predictions={\n",
        "                'xgboost': oof_merged['y_pred_xgb'].values,\n",
        "                'lightgbm': oof_merged['y_pred_lgbm'].values,\n",
        "            },\n",
        "            y_true=oof_merged['y_true'].values\n",
        "        )\n",
        "        \n",
        "        weights = blender.get_weights()\n",
        "        \n",
        "        # Compute ensemble OOF metric\n",
        "        ensemble_preds = (\n",
        "            weights.get('xgboost', 0.5) * oof_merged['y_pred_xgb'].values +\n",
        "            weights.get('lightgbm', 0.5) * oof_merged['y_pred_lgbm'].values\n",
        "        )\n",
        "        ensemble_rmse = np.sqrt(np.mean((ensemble_preds - oof_merged['y_true'].values) ** 2))\n",
        "        \n",
        "        ensemble_results[scenario] = {\n",
        "            'xgb_metric': xgb_results['cv_official_mean'],\n",
        "            'lgbm_metric': lgbm_results['cv_official_mean'],\n",
        "            'xgb_rmse': xgb_results['cv_rmse_mean'],\n",
        "            'lgbm_rmse': lgbm_results['cv_rmse_mean'],\n",
        "            'ensemble_rmse': ensemble_rmse,\n",
        "            'weights': weights,\n",
        "            'xgb_models': xgb_models,\n",
        "            'lgbm_models': lgbm_models,\n",
        "        }\n",
        "        \n",
        "        print(f\"\\n‚úÖ Scenario {scenario} Ensemble Results:\")\n",
        "        print(f\"   XGBoost:  {xgb_results['cv_official_mean']:.4f} (RMSE: {xgb_results['cv_rmse_mean']:.4f})\")\n",
        "        print(f\"   LightGBM: {lgbm_results['cv_official_mean']:.4f} (RMSE: {lgbm_results['cv_rmse_mean']:.4f})\")\n",
        "        print(f\"   Ensemble RMSE: {ensemble_rmse:.4f}\")\n",
        "        print(f\"   Weights:  XGB={weights.get('xgboost', 0.5):.2f}, LGBM={weights.get('lightgbm', 0.5):.2f}\")\n",
        "        \n",
        "        clear_memory()\n",
        "    \n",
        "    # Save ensemble configuration for inference\n",
        "    import json\n",
        "    ensemble_output = {\n",
        "        's1_weights': ensemble_results[1]['weights'],\n",
        "        's2_weights': ensemble_results[2]['weights'],\n",
        "        's1_xgb_metric': ensemble_results[1]['xgb_metric'],\n",
        "        's1_lgbm_metric': ensemble_results[1]['lgbm_metric'],\n",
        "        's2_xgb_metric': ensemble_results[2]['xgb_metric'],\n",
        "        's2_lgbm_metric': ensemble_results[2]['lgbm_metric'],\n",
        "    }\n",
        "    with open(RUN_DIR / 'ensemble_config.json', 'w') as f:\n",
        "        json.dump(ensemble_output, f, indent=2)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä ENSEMBLE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    for s in [1, 2]:\n",
        "        r = ensemble_results[s]\n",
        "        print(f\"  Scenario {s}:\")\n",
        "        print(f\"    XGB: {r['xgb_metric']:.4f}, LGBM: {r['lgbm_metric']:.4f}\")\n",
        "        w = r['weights']\n",
        "        print(f\"    Weights: XGB={w.get('xgboost', 0.5):.0%}, LGBM={w.get('lightgbm', 0.5):.0%}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_ENSEMBLE = True to train XGBoost + LightGBM ensemble\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548b8c8e",
      "metadata": {
        "id": "548b8c8e"
      },
      "source": [
        "## 7. Generate Submission\n",
        "\n",
        "Generate predictions on test data and create submission files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09beced8",
      "metadata": {
        "id": "09beced8"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.1 Build Test Features and Generate Predictions\n",
        "# ==============================================================================\n",
        "import joblib\n",
        "from glob import glob\n",
        "\n",
        "print(\"üì§ Generating submission...\")\n",
        "\n",
        "# Build test features for Scenario 1\n",
        "print(\"  Building S1 test features...\")\n",
        "test_panel = get_panel(split='test', config=data_config, use_cache=True)\n",
        "test_panel_s1 = make_features(test_panel.copy(), scenario=1, mode='test', config=features_config)\n",
        "\n",
        "# Build test features for Scenario 2  \n",
        "print(\"  Building S2 test features...\")\n",
        "test_panel_s2 = make_features(test_panel.copy(), scenario=2, mode='test', config=features_config)\n",
        "\n",
        "# Detect which test samples belong to which scenario\n",
        "test_scenarios = detect_test_scenarios(test_panel)\n",
        "print(f\"  Scenario 1 test series: {len(test_scenarios[1])}\")\n",
        "print(f\"  Scenario 2 test series: {len(test_scenarios[2])}\")\n",
        "\n",
        "# Split features and meta for predictions\n",
        "from src.train import split_features_target_meta\n",
        "\n",
        "# For test data, we need to handle that there's no y_norm column\n",
        "# Use get_feature_matrix_and_meta instead\n",
        "def get_test_features_meta(panel_features, scenario_series):\n",
        "    \"\"\"Extract features and meta for test prediction.\"\"\"\n",
        "    # Filter to scenario-relevant series\n",
        "    if scenario_series:\n",
        "        mask = panel_features.set_index(['country', 'brand_name']).index.isin(scenario_series)\n",
        "        mask = mask.reset_index(drop=True)\n",
        "        panel_subset = panel_features[mask].copy()\n",
        "    else:\n",
        "        panel_subset = panel_features.copy()\n",
        "    \n",
        "    # Separate features from meta\n",
        "    from src.data import META_COLS\n",
        "    feature_cols = [c for c in panel_subset.columns if c not in META_COLS]\n",
        "    meta_cols = [c for c in META_COLS if c in panel_subset.columns]\n",
        "    \n",
        "    X = panel_subset[feature_cols].copy()\n",
        "    meta = panel_subset[meta_cols].copy()\n",
        "    \n",
        "    return X, meta\n",
        "\n",
        "# Get S1 test features\n",
        "X_test_s1, meta_test_s1 = get_test_features_meta(test_panel_s1, test_scenarios[1])\n",
        "print(f\"  S1 test features: {X_test_s1.shape}\")\n",
        "\n",
        "# Get S2 test features\n",
        "X_test_s2, meta_test_s2 = get_test_features_meta(test_panel_s2, test_scenarios[2])\n",
        "print(f\"  S2 test features: {X_test_s2.shape}\")\n",
        "\n",
        "print(f\"\\n  Loading {MODEL_TYPE.upper()} models and predicting...\")\n",
        "\n",
        "# Scenario 1 predictions (average across folds)\n",
        "s1_preds_list = []\n",
        "s1_model_dir = RUN_DIR / 'models_s1'\n",
        "if s1_model_dir.exists():\n",
        "    for model_path in sorted(s1_model_dir.glob('model_fold*.bin')):\n",
        "        model = ModelClass.load(str(model_path), current_model_config)\n",
        "        preds = model.predict(X_test_s1)\n",
        "        s1_preds_list.append(preds)\n",
        "        print(f\"    Loaded {model_path.name}\")\n",
        "\n",
        "if s1_preds_list:\n",
        "    s1_test_preds = np.mean(s1_preds_list, axis=0)\n",
        "    print(f\"  ‚úÖ S1: Averaged {len(s1_preds_list)} fold predictions\")\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è No S1 models found, using baseline predictions (y_norm=1.0)\")\n",
        "    s1_test_preds = np.ones(len(X_test_s1))\n",
        "\n",
        "# Scenario 2 predictions (average across folds)\n",
        "s2_preds_list = []\n",
        "s2_model_dir = RUN_DIR / 'models_s2'\n",
        "if s2_model_dir.exists():\n",
        "    for model_path in sorted(s2_model_dir.glob('model_fold*.bin')):\n",
        "        model = ModelClass.load(str(model_path), current_model_config)\n",
        "        preds = model.predict(X_test_s2)\n",
        "        s2_preds_list.append(preds)\n",
        "        print(f\"    Loaded {model_path.name}\")\n",
        "\n",
        "if s2_preds_list:\n",
        "    s2_test_preds = np.mean(s2_preds_list, axis=0)\n",
        "    print(f\"  ‚úÖ S2: Averaged {len(s2_preds_list)} fold predictions\")\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è No S2 models found, using baseline predictions (y_norm=1.0)\")\n",
        "    s2_test_preds = np.ones(len(X_test_s2))\n",
        "\n",
        "print(f\"\\n  S1 predictions: {len(s1_test_preds):,}\")\n",
        "print(f\"  S2 predictions: {len(s2_test_preds):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfb662d",
      "metadata": {
        "id": "2cfb662d"
      },
      "source": [
        "### 7.2 Create Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cb04ac",
      "metadata": {
        "id": "d6cb04ac"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.2 Create and Save Submission\n",
        "# ==============================================================================\n",
        "\n",
        "# Create submission dataframes\n",
        "# Convert y_norm predictions back to absolute volume using avg_vol\n",
        "\n",
        "# Scenario 1 submission\n",
        "submission_s1 = meta_test_s1[['country', 'brand_name', 'months_postgx']].copy()\n",
        "if 'avg_vol_12m' in meta_test_s1.columns:\n",
        "    submission_s1['volume'] = s1_test_preds * meta_test_s1['avg_vol_12m'].values\n",
        "else:\n",
        "    # If avg_vol not available, predictions are already in volume scale\n",
        "    submission_s1['volume'] = s1_test_preds\n",
        "    print(\"  ‚ö†Ô∏è S1: avg_vol_12m not found, using predictions as-is\")\n",
        "\n",
        "# Scenario 2 submission\n",
        "submission_s2 = meta_test_s2[['country', 'brand_name', 'months_postgx']].copy()\n",
        "if 'avg_vol_12m' in meta_test_s2.columns:\n",
        "    submission_s2['volume'] = s2_test_preds * meta_test_s2['avg_vol_12m'].values\n",
        "else:\n",
        "    submission_s2['volume'] = s2_test_preds\n",
        "    print(\"  ‚ö†Ô∏è S2: avg_vol_12m not found, using predictions as-is\")\n",
        "\n",
        "# Combine submissions\n",
        "submission = pd.concat([submission_s1, submission_s2], ignore_index=True)\n",
        "\n",
        "# Clip negative volumes to 0\n",
        "submission['volume'] = submission['volume'].clip(lower=0)\n",
        "\n",
        "# Validate submission format\n",
        "try:\n",
        "    is_valid, issues = validate_submission_format(submission)\n",
        "    if is_valid:\n",
        "        print(\"‚úÖ Submission format validated\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Validation issues: {issues}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not validate format: {e}\")\n",
        "\n",
        "# Save submission\n",
        "submission_path = Path(SUBMISSIONS_PATH) / f\"submission_{RUN_ID}.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"\\nüìÑ Submission saved to: {submission_path}\")\n",
        "print(f\"  Shape: {submission.shape}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "\n",
        "# Statistics\n",
        "print(f\"\\nüìä Submission Statistics:\")\n",
        "print(f\"  Volume min: {submission['volume'].min():.2f}\")\n",
        "print(f\"  Volume max: {submission['volume'].max():.2f}\")\n",
        "print(f\"  Volume mean: {submission['volume'].mean():.2f}\")\n",
        "print(f\"  Volume median: {submission['volume'].median():.2f}\")\n",
        "\n",
        "# Count by scenario\n",
        "n_s1 = len(submission_s1)\n",
        "n_s2 = len(submission_s2)\n",
        "print(f\"\\n  Scenario 1 rows: {n_s1:,}\")\n",
        "print(f\"  Scenario 2 rows: {n_s2:,}\")\n",
        "print(f\"  Total rows: {len(submission):,}\")\n",
        "\n",
        "# Preview\n",
        "print(f\"\\nüìã Preview:\")\n",
        "display(submission.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfcc4c4",
      "metadata": {
        "id": "1cfcc4c4"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.3 Download Submission (Colab only)\n",
        "# ==============================================================================\n",
        "if IN_COLAB:\n",
        "    print(\"üì• Downloading submission file...\")\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(str(submission_path))\n",
        "        print(\"‚úÖ Download started!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not start download: {e}\")\n",
        "        print(f\"   File is saved at: {submission_path}\")\n",
        "else:\n",
        "    print(f\"üìÑ Submission available at: {submission_path}\")\n",
        "\n",
        "# Also sync to Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        # Copy to Drive submissions folder\n",
        "        import shutil\n",
        "        drive_submission_path = f\"{SUBMISSIONS_PATH}/submission_{RUN_ID}.csv\"\n",
        "        shutil.copy(str(submission_path), drive_submission_path)\n",
        "        print(f\"‚òÅÔ∏è Saved to Google Drive: {drive_submission_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not save to Drive: {e}\")\n",
        "\n",
        "# Also save run summary\n",
        "try:\n",
        "    summary = {\n",
        "        'run_id': RUN_ID,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'training_mode': TRAINING_MODE,\n",
        "        'n_folds': N_FOLDS,\n",
        "        'gpu_used': USE_GPU and GPU_AVAILABLE,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'submission_path': str(submission_path),\n",
        "        'submission_rows': len(submission),\n",
        "    }\n",
        "    \n",
        "    if 's1_cv_results' in dir():\n",
        "        summary['s1_cv_official_mean'] = s1_cv_results.get('cv_official_mean')\n",
        "        summary['s1_cv_official_std'] = s1_cv_results.get('cv_official_std')\n",
        "    \n",
        "    if 's2_cv_results' in dir():\n",
        "        summary['s2_cv_official_mean'] = s2_cv_results.get('cv_official_mean')\n",
        "        summary['s2_cv_official_std'] = s2_cv_results.get('cv_official_std')\n",
        "    \n",
        "    summary_path = RUN_DIR / 'run_summary.json'\n",
        "    import json\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2, default=str)\n",
        "    print(f\"üìÑ Run summary saved: {summary_path}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Could not save run summary: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8de5b70",
      "metadata": {},
      "source": [
        "## 8. Utilities\n",
        "\n",
        "Helper functions for common operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58871fc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 8.1 Utility Functions\n",
        "# ==============================================================================\n",
        "\n",
        "def show_memory():\n",
        "    \"\"\"Display current memory usage.\"\"\"\n",
        "    mem = get_memory_usage()\n",
        "    print(f\"üíæ Memory Usage:\")\n",
        "    print(f\"  Process: {mem.get('process_rss_gb', 0):.2f} GB\")\n",
        "    print(f\"  System: {mem.get('system_used_percent', 0):.1f}% used\")\n",
        "    if 'gpu_allocated_gb' in mem:\n",
        "        print(f\"  GPU: {mem['gpu_allocated_gb']:.2f} GB allocated\")\n",
        "\n",
        "def free_memory():\n",
        "    \"\"\"Free unused memory.\"\"\"\n",
        "    before = get_memory_usage().get('process_rss_gb', 0)\n",
        "    clear_memory()\n",
        "    after = get_memory_usage().get('process_rss_gb', 0)\n",
        "    print(f\"üßπ Freed {max(0, before - after):.2f} GB\")\n",
        "\n",
        "def download_artifacts():\n",
        "    \"\"\"Download all artifacts as a zip file (Colab only).\"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(f\"üìÅ Artifacts at: {RUN_DIR}\")\n",
        "        return\n",
        "    \n",
        "    import shutil\n",
        "    zip_path = f\"/content/artifacts_{RUN_ID}.zip\"\n",
        "    shutil.make_archive(zip_path.replace('.zip', ''), 'zip', str(RUN_DIR))\n",
        "    \n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "    print(f\"üì¶ Downloaded: artifacts_{RUN_ID}.zip\")\n",
        "\n",
        "def restart_runtime():\n",
        "    \"\"\"Restart Colab runtime to free memory.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        import os\n",
        "        os.kill(os.getpid(), 9)\n",
        "\n",
        "def check_gpu():\n",
        "    \"\"\"Check GPU status and memory.\"\"\"\n",
        "    print(\"üñ•Ô∏è GPU Status:\")\n",
        "    if IN_COLAB:\n",
        "        !nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader 2>/dev/null || print(\"  GPU not available\")\n",
        "    else:\n",
        "        gpu_info = get_gpu_info()\n",
        "        if gpu_info.get('gpu_available'):\n",
        "            print(f\"  Device: {gpu_info.get('device_name', 'Unknown')}\")\n",
        "            print(f\"  CUDA: {gpu_info.get('cuda_version', 'N/A')}\")\n",
        "        else:\n",
        "            print(\"  GPU not available\")\n",
        "\n",
        "def list_available_configs():\n",
        "    \"\"\"List all available model configurations.\"\"\"\n",
        "    print(\"üìã Available Model Configurations:\")\n",
        "    for model_name, cfg in model_configs.items():\n",
        "        sweep_configs = cfg.get('sweep_configs', [])\n",
        "        n_configs = len(sweep_configs) if sweep_configs else 0\n",
        "        active = cfg.get('active_config_id', 'none')\n",
        "        print(f\"\\n  {model_name.upper()}:\")\n",
        "        print(f\"    Active config: {active}\")\n",
        "        print(f\"    Sweep configs: {n_configs}\")\n",
        "        if sweep_configs:\n",
        "            for sc in sweep_configs[:3]:\n",
        "                print(f\"      - {sc.get('id', 'unnamed')}: {sc.get('description', '')[:40]}\")\n",
        "            if len(sweep_configs) > 3:\n",
        "                print(f\"      ... and {len(sweep_configs) - 3} more\")\n",
        "\n",
        "def save_run_summary():\n",
        "    \"\"\"Save a summary of the current run.\"\"\"\n",
        "    summary = {\n",
        "        'run_id': RUN_ID,\n",
        "        'model_type': MODEL_TYPE,\n",
        "        'training_mode': TRAINING_MODE,\n",
        "        'n_folds': N_FOLDS,\n",
        "        'gpu_used': USE_GPU and GPU_AVAILABLE,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "    }\n",
        "    \n",
        "    if 's1_cv_results' in dir():\n",
        "        summary['s1_cv_official_mean'] = s1_cv_results.get('cv_official_mean')\n",
        "        summary['s1_cv_official_std'] = s1_cv_results.get('cv_official_std')\n",
        "    \n",
        "    if 's2_cv_results' in dir():\n",
        "        summary['s2_cv_official_mean'] = s2_cv_results.get('cv_official_mean')\n",
        "        summary['s2_cv_official_std'] = s2_cv_results.get('cv_official_std')\n",
        "    \n",
        "    summary_path = RUN_DIR / 'run_summary.json'\n",
        "    import json\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(summary, f, indent=2, default=str)\n",
        "    \n",
        "    print(f\"üìÑ Run summary saved to: {summary_path}\")\n",
        "    return summary\n",
        "\n",
        "print(\"üõ†Ô∏è Utility functions available:\")\n",
        "print(\"  - show_memory(): Display memory usage\")\n",
        "print(\"  - free_memory(): Free unused memory\")\n",
        "print(\"  - check_gpu(): Check GPU status and memory\")\n",
        "print(\"  - download_artifacts(): Download all run artifacts\")\n",
        "print(\"  - restart_runtime(): Restart Colab runtime\")\n",
        "print(\"  - list_available_configs(): List model configurations\")\n",
        "print(\"  - save_run_summary(): Save run summary to file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648cb0bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 8.2 Data Setup Helper (if data is not automatically found)\n",
        "# ==============================================================================\n",
        "# Run this cell if your data is not in the expected location\n",
        "\n",
        "def setup_data_from_drive():\n",
        "    \"\"\"\n",
        "    Helper to set up data from Google Drive.\n",
        "    \n",
        "    This function helps locate and link your data if it's in a different location.\n",
        "    \"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(\"‚ÑπÔ∏è Not in Colab - using local data paths\")\n",
        "        return\n",
        "    \n",
        "    print(\"üîç Searching for data directories on Google Drive...\")\n",
        "    \n",
        "    # Common locations to check\n",
        "    search_paths = [\n",
        "        \"/content/drive/MyDrive/novartis-datathon-2025/data\",\n",
        "        \"/content/drive/MyDrive/Colab Notebooks/novartis_data\",\n",
        "        \"/content/drive/MyDrive/data\",\n",
        "        \"/content/drive/MyDrive/novartis/data\",\n",
        "    ]\n",
        "    \n",
        "    found_path = None\n",
        "    for path in search_paths:\n",
        "        if os.path.exists(path):\n",
        "            # Check if it has the expected structure\n",
        "            raw_train = os.path.join(path, \"raw\", \"TRAIN\")\n",
        "            raw_test = os.path.join(path, \"raw\", \"TEST\")\n",
        "            \n",
        "            if os.path.exists(raw_train) or os.path.exists(raw_test):\n",
        "                found_path = path\n",
        "                print(f\"  ‚úÖ Found data at: {path}\")\n",
        "                break\n",
        "            else:\n",
        "                print(f\"  ‚ö†Ô∏è Found {path} but missing raw/TRAIN or raw/TEST\")\n",
        "    \n",
        "    if found_path:\n",
        "        # Create symlink\n",
        "        local_data = os.path.join(PROJECT_PATH, \"data\")\n",
        "        if os.path.islink(local_data):\n",
        "            os.unlink(local_data)\n",
        "        elif os.path.exists(local_data):\n",
        "            import shutil\n",
        "            shutil.rmtree(local_data)\n",
        "        \n",
        "        os.symlink(found_path, local_data)\n",
        "        print(f\"  üîó Linked data directory\")\n",
        "        \n",
        "        # List contents\n",
        "        print(f\"\\nüìÇ Data contents:\")\n",
        "        for item in os.listdir(found_path):\n",
        "            item_path = os.path.join(found_path, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                subitems = os.listdir(item_path)[:5]\n",
        "                print(f\"  üìÅ {item}/ ({len(os.listdir(item_path))} items)\")\n",
        "                for si in subitems:\n",
        "                    print(f\"      - {si}\")\n",
        "            else:\n",
        "                print(f\"  üìÑ {item}\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Data not found. Please:\")\n",
        "        print(\"   1. Upload your data to Google Drive\")\n",
        "        print(\"   2. Expected structure:\")\n",
        "        print(\"      /content/drive/MyDrive/novartis-datathon-2025/data/\")\n",
        "        print(\"        ‚îú‚îÄ‚îÄ raw/\")\n",
        "        print(\"        ‚îÇ   ‚îú‚îÄ‚îÄ TRAIN/\")\n",
        "        print(\"        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ volume.parquet\")\n",
        "        print(\"        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generics.parquet\")\n",
        "        print(\"        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ medicine_info.parquet\")\n",
        "        print(\"        ‚îÇ   ‚îî‚îÄ‚îÄ TEST/\")\n",
        "        print(\"        ‚îÇ       ‚îú‚îÄ‚îÄ volume.parquet\")\n",
        "        print(\"        ‚îÇ       ‚îú‚îÄ‚îÄ generics.parquet\")\n",
        "        print(\"        ‚îÇ       ‚îî‚îÄ‚îÄ medicine_info.parquet\")\n",
        "        print(\"        ‚îî‚îÄ‚îÄ processed/ (optional)\")\n",
        "\n",
        "# Uncomment to run:\n",
        "# setup_data_from_drive()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b426d2f",
      "metadata": {},
      "source": [
        "## üìä Summary\n",
        "\n",
        "This notebook provides a complete training and submission pipeline for the Novartis Datathon 2025 competition.\n",
        "\n",
        "### ‚úÖ Features Implemented\n",
        "- **Multi-Model Support**: 7 models available (XGBoost, LightGBM, CatBoost, Linear, Neural Network, Hybrid, ARIHOW)\n",
        "- **Training Modes**: Cross-validation, full training, hyperparameter sweep\n",
        "- **GPU Acceleration**: Automatic detection and utilization for tree models and neural networks\n",
        "- **Google Drive Integration**: Seamless data loading from shared Drive folders\n",
        "- **Memory Management**: Garbage collection and memory monitoring\n",
        "- **Robust Error Handling**: Graceful degradation and informative error messages\n",
        "- **Artifact Management**: Saves models, predictions, and metrics to organized directories\n",
        "\n",
        "### ü§ñ Available Models (Priority Order)\n",
        "\n",
        "| Priority | Model | Config File | Description |\n",
        "|----------|-------|-------------|-------------|\n",
        "| 1 | XGBoost | `model_xgb.yaml` | Primary model - best official_metric performance |\n",
        "| 2 | LightGBM | `model_lgbm.yaml` | Secondary - fast, good for ensemble |\n",
        "| 2 | Hybrid | `model_hybrid.yaml` | Physics decay + ML residual learning |\n",
        "| 3 | CatBoost | `model_cat.yaml` | Tertiary - ensemble diversity |\n",
        "| 4 | Linear | `model_linear.yaml` | Baseline (Ridge/Lasso/ElasticNet/Huber) |\n",
        "| 4 | ARIHOW | `model_arihow.yaml` | ARIMA + Holt-Winters hybrid |\n",
        "| 5 | Neural Network | `model_nn.yaml` | Experimental PyTorch MLP |\n",
        "\n",
        "### üéØ Competition Metrics\n",
        "- **Scenario 1**: Forecast months 0-23 (pre-entry data only)\n",
        "- **Scenario 2**: Forecast months 6-23 (has early months 0-5)\n",
        "- **Official Metric**: PE (Prediction Error) - lower is better\n",
        "\n",
        "### üìÅ Output Files\n",
        "All outputs are saved to:\n",
        "- `artifacts/{run_id}/` - Models, metrics, and predictions\n",
        "- `submissions/` - Final submission CSV files\n",
        "- Google Drive (if in Colab): `/content/drive/MyDrive/novartis-datathon-2025/`\n",
        "\n",
        "### üîß Configuration Options\n",
        "| Option | Description | Default |\n",
        "|--------|-------------|---------|\n",
        "| `MODEL_TYPE` | Model architecture | `xgboost` |\n",
        "| `TRAINING_MODE` | cv, quick, sweep, sweep_cv, ensemble, compare | `cv` |\n",
        "| `N_FOLDS` | Cross-validation folds | `5` |\n",
        "| `USE_GPU` | Enable GPU acceleration | `True` |\n",
        "| `SEED` | Reproducibility seed | `42` |\n",
        "\n",
        "### üìã Config Files Structure\n",
        "Each model config (`configs/model_*.yaml`) contains:\n",
        "- `model`: Name, task type, priority\n",
        "- `gpu`: GPU settings (enabled, device_id)\n",
        "- `sweep`: Hyperparameter sweep configuration\n",
        "- `sweep_configs`: Named parameter presets\n",
        "- `scenario_best_params`: Best params per scenario from previous sweeps\n",
        "- `params`: Default model parameters"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
