{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64988215",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armanfeili/novartis_datathon_2025/blob/Arman/notebooks/colab/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d532273",
      "metadata": {
        "id": "2d532273"
      },
      "source": [
        "# üß¨ Novartis Datathon 2025 - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a **complete end-to-end pipeline** for the Novartis Datathon 2025:\n",
        "\n",
        "1. **üîß Environment Setup** - Mount Drive, clone repo, install dependencies\n",
        "2. **üìä Data Loading** - Load raw data and build panels\n",
        "3. **üî¨ Feature Engineering** - Build scenario-specific features  \n",
        "4. **üèãÔ∏è Model Training** - Train CatBoost models with cross-validation\n",
        "5. **üìà Evaluation** - Analyze model performance\n",
        "6. **üì§ Submission** - Generate competition submission files\n",
        "\n",
        "---\n",
        "\n",
        "**Quick Start:**\n",
        "1. Run all cells in order\n",
        "2. Data should be placed in `data/raw/TRAIN/` and `data/raw/TEST/`\n",
        "3. Trained models and submissions are saved to Google Drive\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7cb47e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7cb47e",
        "outputId": "19aa1c88-b017-42fa-b3f2-6e307d2ea8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted successfully\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.1 Detect Environment and Mount Google Drive\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect if running in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "print(f\"üñ•Ô∏è  Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted successfully\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - using local paths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd0aa8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd0aa8d",
        "outputId": "aad58a59-705d-4795-85cb-22bf0e22383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Repository exists at /content/drive/MyDrive/novartis_datathon_2025. Pulling latest changes...\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10 (delta 6), reused 10 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (10/10), 8.06 KiB | 26.00 KiB/s, done.\n",
            "From https://github.com/armanfeili/novartis_datathon_2025\n",
            " * branch            Arman      -> FETCH_HEAD\n",
            "   67c14aa..5c33709  Arman      -> origin/Arman\n",
            "HEAD is now at 5c33709 project setup - 3\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "\n",
            "üìÅ Project Path: /content/drive/MyDrive/novartis_datathon_2025\n",
            "üìÅ Data Path: /content/drive/MyDrive/novartis-datathon-2025/data\n",
            "üìÅ Artifacts Path: /content/drive/MyDrive/novartis-datathon-2025/artifacts\n",
            "üìÅ Submissions Path: /content/drive/MyDrive/novartis-datathon-2025/submissions\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.2 Clone Repository and Set Paths\n",
        "# ==============================================================================\n",
        "import os\n",
        "\n",
        "# --- Configuration (MODIFY THESE) ---\n",
        "REPO_URL = \"https://github.com/armanfeili/novartis_datathon_2025.git\"\n",
        "BRANCH = \"Arman\"  # Change to your working branch\n",
        "\n",
        "# Paths depend on environment\n",
        "if IN_COLAB:\n",
        "    DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "    PROJECT_PATH = \"/content/novartis_datathon_2025\"  # Clone to /content for speed\n",
        "    DATA_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/data\"  # Data on Drive\n",
        "    ARTIFACTS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/artifacts\"\n",
        "    SUBMISSIONS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/submissions\"\n",
        "else:\n",
        "    # Local paths (relative to notebook location)\n",
        "    PROJECT_PATH = str(Path.cwd().parent.parent)\n",
        "    DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
        "    ARTIFACTS_PATH = os.path.join(PROJECT_PATH, \"artifacts\")\n",
        "    SUBMISSIONS_PATH = os.path.join(PROJECT_PATH, \"submissions\")\n",
        "# --------------------------------\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone or update repository\n",
        "    if not os.path.exists(PROJECT_PATH):\n",
        "        print(f\"üì• Cloning repository...\")\n",
        "        !git clone --branch {BRANCH} {REPO_URL} {PROJECT_PATH}\n",
        "    else:\n",
        "        print(f\"üìÇ Repository exists. Pulling latest changes...\")\n",
        "        %cd {PROJECT_PATH}\n",
        "        !git fetch origin {BRANCH}\n",
        "        !git reset --hard origin/{BRANCH}\n",
        "    \n",
        "    %cd {PROJECT_PATH}\n",
        "    \n",
        "    # Create symlinks to Drive data (if data is on Drive)\n",
        "    if os.path.exists(DATA_PATH):\n",
        "        local_data = os.path.join(PROJECT_PATH, \"data\")\n",
        "        if not os.path.exists(local_data):\n",
        "            !ln -s {DATA_PATH} {local_data}\n",
        "            print(f\"üîó Linked data directory from Drive\")\n",
        "\n",
        "# Create required directories\n",
        "for path in [DATA_PATH, ARTIFACTS_PATH, SUBMISSIONS_PATH]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Print paths\n",
        "print(f\"\\nüìÅ Project: {PROJECT_PATH}\")\n",
        "print(f\"üìÅ Data: {DATA_PATH}\")\n",
        "print(f\"üìÅ Artifacts: {ARTIFACTS_PATH}\")\n",
        "print(f\"üìÅ Submissions: {SUBMISSIONS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd7f350",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfd7f350",
        "outputId": "7ea6c438-55a0-40db-c862-e3d25e3f73c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  ‚úÖ torch\n",
            "  ‚úÖ numpy\n",
            "  ‚úÖ pandas\n",
            "  ‚úÖ lightgbm\n",
            "  ‚úÖ xgboost\n",
            "  ‚úÖ catboost\n",
            "  ‚úÖ sklearn\n",
            "  ‚úÖ yaml\n",
            "\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.3 Install Dependencies\n",
        "# ==============================================================================\n",
        "import subprocess\n",
        "\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Install from colab requirements\n",
        "!pip install -q -r env/colab_requirements.txt\n",
        "\n",
        "# Verify key packages\n",
        "import importlib\n",
        "\n",
        "packages = [\n",
        "    ('numpy', 'numpy'),\n",
        "    ('pandas', 'pandas'),\n",
        "    ('sklearn', 'scikit-learn'),\n",
        "    ('yaml', 'pyyaml'),\n",
        "    ('tqdm', 'tqdm'),\n",
        "    ('catboost', 'catboost'),\n",
        "    ('lightgbm', 'lightgbm'),\n",
        "    ('xgboost', 'xgboost'),\n",
        "    ('pyarrow', 'pyarrow'),\n",
        "]\n",
        "\n",
        "print(\"\\nüìã Package Status:\")\n",
        "for import_name, pkg_name in packages:\n",
        "    try:\n",
        "        mod = importlib.import_module(import_name)\n",
        "        version = getattr(mod, '__version__', 'installed')\n",
        "        print(f\"  ‚úÖ {pkg_name}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"  ‚ùå {pkg_name}: not installed\")\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a8cd44",
      "metadata": {
        "id": "00a8cd44"
      },
      "source": [
        "## 2. Import Modules and Verify Environment\n",
        "\n",
        "Import project modules and verify GPU availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63474d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63474d74",
        "outputId": "053ae606-25b3-4d85-cfc8-c460de74a61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üñ•Ô∏è  Device: cpu\n",
            "\n",
            "‚úÖ All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 2.1 Import Project Modules\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure project root is in path\n",
        "if PROJECT_PATH not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_PATH)\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Project imports\n",
        "from src.utils import (\n",
        "    load_config, set_seed, setup_logging, timer, \n",
        "    get_device, get_gpu_info, print_environment_info,\n",
        "    clear_memory, get_memory_usage, optimize_dataframe_memory\n",
        ")\n",
        "from src.data import (\n",
        "    get_panel, load_raw_data, prepare_base_panel, \n",
        "    compute_pre_entry_stats, handle_missing_values,\n",
        "    META_COLS\n",
        ")\n",
        "from src.features import (\n",
        "    get_features, make_features, split_features_target_meta,\n",
        "    get_feature_columns, SCENARIO_CONFIG\n",
        ")\n",
        "from src.train import train_scenario_model, run_cross_validation\n",
        "from src.evaluate import compute_metric1, compute_metric2, compute_per_series_error\n",
        "from src.inference import (\n",
        "    generate_submission, detect_test_scenarios, \n",
        "    validate_submission_format, save_submission_with_versioning\n",
        ")\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2.2 Display Environment Information\n",
        "# ==============================================================================\n",
        "print_environment_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "286fbdcc",
      "metadata": {
        "id": "286fbdcc"
      },
      "source": [
        "## 3. Load Configuration and Set Seed\n",
        "\n",
        "Load all configuration files and set random seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c891f807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c891f807",
        "outputId": "7d082df9-35cd-4f14-ffbb-1bf4c86214de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configurations loaded:\n",
            "  - Data config: ['drive', 'local', 'files', 'keys', 'dates', 'columns', 'validation']\n",
            "  - Features config: ['feature_groups', 'lags', 'rolling', 'diff', 'time_features', 'interactions', 'selection', 'encoding']\n",
            "  - Run config: ['experiment', 'run', 'reproducibility', 'cv', 'paths', 'output', 'metrics', 'logging', 'drive', 'hardware']\n",
            "  - Model configs: ['lightgbm', 'xgboost', 'catboost', 'linear', 'neural_network']\n",
            "\n",
            "üé≤ Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 3.1 Load Configurations\n",
        "# ==============================================================================\n",
        "data_config = load_config('configs/data.yaml')\n",
        "features_config = load_config('configs/features.yaml')\n",
        "run_config = load_config('configs/run_defaults.yaml')\n",
        "model_config = load_config('configs/model_cat.yaml')  # Hero model: CatBoost\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = run_config['reproducibility']['seed']\n",
        "set_seed(SEED)\n",
        "\n",
        "# Setup logging\n",
        "setup_logging(level=run_config.get('logging', {}).get('level', 'INFO'))\n",
        "\n",
        "print(\"üìã Configurations loaded:\")\n",
        "print(f\"  - Random seed: {SEED}\")\n",
        "print(f\"  - Scenarios: {list(run_config['scenarios'].keys())}\")\n",
        "print(f\"  - Model: {model_config.get('model_type', 'catboost')}\")\n",
        "\n",
        "# Display scenario details\n",
        "print(f\"\\nüìÖ Scenario Configuration:\")\n",
        "for s_name, s_config in run_config['scenarios'].items():\n",
        "    print(f\"  {s_name}:\")\n",
        "    print(f\"    Forecast: months {s_config['forecast_start']} to {s_config['forecast_end']}\")\n",
        "    print(f\"    Feature cutoff: month {s_config['feature_cutoff']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafc46c9",
      "metadata": {
        "id": "dafc46c9"
      },
      "source": [
        "## 4. Load and Explore Data\n",
        "\n",
        "Load the training and test data panels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4881a89e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4881a89e",
        "outputId": "c4ae155e-a98c-439f-ecda-788964482add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Data Directories:\n",
            "  Raw: /content/drive/MyDrive/novartis-datathon-2025/data/raw (exists: True)\n",
            "  Interim: /content/drive/MyDrive/novartis-datathon-2025/data/interim (exists: True)\n",
            "  Processed: /content/drive/MyDrive/novartis-datathon-2025/data/processed (exists: True)\n",
            "\n",
            "üìÑ Available raw files (0):\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.1 Load Training Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading training data...\")\n",
        "\n",
        "with timer(\"Load train panel\"):\n",
        "    train_panel = get_panel(split='train', config=data_config, use_cache=True)\n",
        "\n",
        "# Display statistics\n",
        "n_series = train_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "print(f\"\\nüìä Training Panel Statistics:\")\n",
        "print(f\"  Shape: {train_panel.shape[0]:,} rows √ó {train_panel.shape[1]} columns\")\n",
        "print(f\"  Unique series: {n_series:,}\")\n",
        "print(f\"  Time range: {train_panel['months_postgx'].min()} to {train_panel['months_postgx'].max()}\")\n",
        "\n",
        "# Bucket distribution\n",
        "bucket_dist = train_panel[['country', 'brand_name', 'bucket']].drop_duplicates()['bucket'].value_counts()\n",
        "print(f\"\\nü™£ Bucket Distribution:\")\n",
        "for bucket, count in bucket_dist.items():\n",
        "    pct = count / n_series * 100\n",
        "    print(f\"  Bucket {bucket}: {count:,} series ({pct:.1f}%)\")\n",
        "\n",
        "# Memory usage\n",
        "mem_mb = train_panel.memory_usage(deep=True).sum() / (1024**2)\n",
        "print(f\"\\nüíæ Memory: {mem_mb:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9c8aac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "6b9c8aac",
        "outputId": "62bddad9-70b0-4010-ad25-55c5a9b7ef0a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1657483188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note: Update configs/data.yaml with your actual file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üìä Loaded {len(raw_data)} datasets:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/novartis_datathon_2025/src/data.py\u001b[0m in \u001b[0;36mload_raw_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Load Raw Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.2 Load Test Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading test data...\")\n",
        "\n",
        "with timer(\"Load test panel\"):\n",
        "    test_panel = get_panel(split='test', config=data_config, use_cache=True)\n",
        "\n",
        "# Detect scenarios\n",
        "test_scenarios = detect_test_scenarios(test_panel)\n",
        "n_test_series = test_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "\n",
        "print(f\"\\nüìä Test Panel Statistics:\")\n",
        "print(f\"  Shape: {test_panel.shape[0]:,} rows √ó {test_panel.shape[1]} columns\")\n",
        "print(f\"  Unique series: {n_test_series:,}\")\n",
        "print(f\"  Scenario 1 series: {len(test_scenarios[1]):,}\")\n",
        "print(f\"  Scenario 2 series: {len(test_scenarios[2]):,}\")\n",
        "\n",
        "# Clear memory\n",
        "clear_memory()\n",
        "print(f\"\\nüßπ Memory cleared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ae59ab",
      "metadata": {
        "id": "98ae59ab"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 4.3 Quick Data Exploration\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. y_norm distribution\n",
        "ax = axes[0, 0]\n",
        "train_panel['y_norm'].hist(bins=50, ax=ax, color='steelblue', edgecolor='white')\n",
        "ax.axvline(x=1.0, color='red', linestyle='--', label='No erosion (1.0)')\n",
        "ax.axvline(x=0.25, color='orange', linestyle='--', label='Bucket 1 threshold')\n",
        "ax.set_xlabel('Normalized Volume (y_norm)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Distribution of y_norm')\n",
        "ax.legend()\n",
        "\n",
        "# 2. Mean erosion curve by bucket\n",
        "ax = axes[0, 1]\n",
        "for bucket in [1, 2]:\n",
        "    bucket_data = train_panel[train_panel['bucket'] == bucket]\n",
        "    erosion_by_month = bucket_data.groupby('months_postgx')['y_norm'].mean()\n",
        "    ax.plot(erosion_by_month.index, erosion_by_month.values, \n",
        "            label=f'Bucket {bucket}', linewidth=2)\n",
        "ax.axhline(y=1.0, color='gray', linestyle=':', alpha=0.7)\n",
        "ax.set_xlabel('Months Post Generic Entry')\n",
        "ax.set_ylabel('Mean Normalized Volume')\n",
        "ax.set_title('Erosion Curves by Bucket')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Number of generics over time\n",
        "ax = axes[1, 0]\n",
        "ngxs_by_month = train_panel.groupby('months_postgx')['n_gxs'].mean()\n",
        "ax.bar(ngxs_by_month.index, ngxs_by_month.values, color='forestgreen', alpha=0.7)\n",
        "ax.set_xlabel('Months Post Generic Entry')\n",
        "ax.set_ylabel('Mean Number of Generics')\n",
        "ax.set_title('Average Generic Competition Over Time')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Hospital rate distribution\n",
        "ax = axes[1, 1]\n",
        "if 'hospital_rate' in train_panel.columns:\n",
        "    hr_by_series = train_panel.groupby(['country', 'brand_name'])['hospital_rate'].first()\n",
        "    hr_by_series.hist(bins=30, ax=ax, color='purple', edgecolor='white', alpha=0.7)\n",
        "    ax.set_xlabel('Hospital Rate (%)')\n",
        "    ax.set_ylabel('Number of Series')\n",
        "    ax.set_title('Hospital Rate Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Data exploration complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba3b589",
      "metadata": {
        "id": "eba3b589"
      },
      "source": [
        "## 5. Feature Engineering\n",
        "\n",
        "Build scenario-specific features for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96056c47",
      "metadata": {
        "id": "96056c47"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 5.1 Build Features for Both Scenarios\n",
        "# ==============================================================================\n",
        "\n",
        "# Build Scenario 1 features (forecast months 0-23 using pre-entry only)\n",
        "print(\"üî¨ Building Scenario 1 features...\")\n",
        "with timer(\"Scenario 1 features\"):\n",
        "    X_train_s1, y_train_s1, meta_train_s1 = get_features(\n",
        "        split='train', scenario=1, mode='train',\n",
        "        data_config=data_config, features_config=features_config,\n",
        "        use_cache=True\n",
        "    )\n",
        "print(f\"  X shape: {X_train_s1.shape}\")\n",
        "print(f\"  y shape: {y_train_s1.shape}\")\n",
        "print(f\"  Features: {len(X_train_s1.columns)}\")\n",
        "\n",
        "# Build Scenario 2 features (forecast months 6-23 using pre-entry + months 0-5)\n",
        "print(\"\\nüî¨ Building Scenario 2 features...\")\n",
        "with timer(\"Scenario 2 features\"):\n",
        "    X_train_s2, y_train_s2, meta_train_s2 = get_features(\n",
        "        split='train', scenario=2, mode='train',\n",
        "        data_config=data_config, features_config=features_config,\n",
        "        use_cache=True\n",
        "    )\n",
        "print(f\"  X shape: {X_train_s2.shape}\")\n",
        "print(f\"  y shape: {y_train_s2.shape}\")\n",
        "print(f\"  Features: {len(X_train_s2.columns)}\")\n",
        "\n",
        "# Display some feature examples\n",
        "print(f\"\\nüìã Sample Features (Scenario 1):\")\n",
        "print(f\"  {list(X_train_s1.columns[:10])}...\")\n",
        "\n",
        "# Check for early erosion features in S2 only\n",
        "s2_only_features = [c for c in X_train_s2.columns if 'erosion_0' in c or 'avg_vol_0' in c]\n",
        "if s2_only_features:\n",
        "    print(f\"\\nüìã Scenario 2 Specific Features:\")\n",
        "    print(f\"  {s2_only_features[:5]}...\")\n",
        "\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22178dd4",
      "metadata": {
        "id": "22178dd4"
      },
      "source": [
        "## 6. Model Training\n",
        "\n",
        "Train CatBoost models for both scenarios using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22078bc1",
      "metadata": {
        "id": "22078bc1"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.1 Training Configuration\n",
        "# ==============================================================================\n",
        "\n",
        "# Training settings\n",
        "N_FOLDS = 5\n",
        "MODEL_TYPE = 'catboost'  # Options: catboost, lightgbm, xgboost, linear\n",
        "\n",
        "# Create run ID\n",
        "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = Path(ARTIFACTS_PATH) / RUN_ID\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üèÉ Training Configuration:\")\n",
        "print(f\"  Run ID: {RUN_ID}\")\n",
        "print(f\"  Model: {MODEL_TYPE}\")\n",
        "print(f\"  CV Folds: {N_FOLDS}\")\n",
        "print(f\"  Artifacts: {RUN_DIR}\")\n",
        "\n",
        "# Check if GPU is available for CatBoost\n",
        "gpu_info = get_gpu_info()\n",
        "if gpu_info['gpu_available'] and gpu_info.get('cuda_version'):\n",
        "    print(f\"  üöÄ GPU: {gpu_info['device_name']} - will use GPU training\")\n",
        "    use_gpu = True\n",
        "else:\n",
        "    print(f\"  üíª Using CPU training\")\n",
        "    use_gpu = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417260a5",
      "metadata": {
        "id": "417260a5"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.2 Train Scenario 1 Model\n",
        "# ==============================================================================\n",
        "from src.models import get_model_class\n",
        "from src.train import compute_sample_weights\n",
        "from src.validation import get_fold_series\n",
        "\n",
        "print(\"üèãÔ∏è Training Scenario 1 model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get model class and config\n",
        "ModelClass = get_model_class(MODEL_TYPE)\n",
        "\n",
        "# Prepare model config with optional GPU\n",
        "s1_model_config = model_config.copy()\n",
        "if use_gpu and MODEL_TYPE == 'catboost':\n",
        "    s1_model_config['params'] = {**s1_model_config.get('params', {}), **{'task_type': 'GPU', 'devices': '0'}}\n",
        "\n",
        "# Train with cross-validation\n",
        "s1_cv_results = run_cross_validation(\n",
        "    X=X_train_s1,\n",
        "    y=y_train_s1,\n",
        "    meta_df=meta_train_s1,\n",
        "    scenario=1,\n",
        "    model_config=s1_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_dir=RUN_DIR / 'models_s1',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 1 Training Complete\")\n",
        "print(f\"  Mean CV Metric: {s1_cv_results['mean_score']:.6f} ¬± {s1_cv_results['std_score']:.6f}\")\n",
        "\n",
        "# Save S1 OOF predictions\n",
        "oof_s1 = pd.DataFrame({\n",
        "    'y_true': y_train_s1,\n",
        "    'y_pred': s1_cv_results['oof_predictions'],\n",
        "})\n",
        "oof_s1.to_csv(RUN_DIR / 'oof_s1.csv', index=False)\n",
        "\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddfd0994",
      "metadata": {
        "id": "ddfd0994"
      },
      "source": [
        "### 6.3 Train Scenario 2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b7bf71",
      "metadata": {
        "id": "d6b7bf71"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.3 Train Scenario 2 Model\n",
        "# ==============================================================================\n",
        "print(\"üèãÔ∏è Training Scenario 2 model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Prepare model config\n",
        "s2_model_config = model_config.copy()\n",
        "if use_gpu and MODEL_TYPE == 'catboost':\n",
        "    s2_model_config['params'] = {**s2_model_config.get('params', {}), **{'task_type': 'GPU', 'devices': '0'}}\n",
        "\n",
        "# Train with cross-validation\n",
        "s2_cv_results = run_cross_validation(\n",
        "    X=X_train_s2,\n",
        "    y=y_train_s2,\n",
        "    meta_df=meta_train_s2,\n",
        "    scenario=2,\n",
        "    model_config=s2_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_dir=RUN_DIR / 'models_s2',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 2 Training Complete\")\n",
        "print(f\"  Mean CV Metric: {s2_cv_results['mean_score']:.6f} ¬± {s2_cv_results['std_score']:.6f}\")\n",
        "\n",
        "# Save S2 OOF predictions\n",
        "oof_s2 = pd.DataFrame({\n",
        "    'y_true': y_train_s2,\n",
        "    'y_pred': s2_cv_results['oof_predictions'],\n",
        "})\n",
        "oof_s2.to_csv(RUN_DIR / 'oof_s2.csv', index=False)\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Scenario 1 CV: {s1_cv_results['mean_score']:.6f} ¬± {s1_cv_results['std_score']:.6f}\")\n",
        "print(f\"  Scenario 2 CV: {s2_cv_results['mean_score']:.6f} ¬± {s2_cv_results['std_score']:.6f}\")\n",
        "print(f\"  Models saved to: {RUN_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548b8c8e",
      "metadata": {
        "id": "548b8c8e"
      },
      "source": [
        "## 7. Generate Submission\n",
        "\n",
        "Generate predictions on test data and create submission files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09beced8",
      "metadata": {
        "id": "09beced8"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.1 Build Test Features and Generate Predictions\n",
        "# ==============================================================================\n",
        "import joblib\n",
        "\n",
        "print(\"üì§ Generating submission...\")\n",
        "\n",
        "# Build test features for Scenario 1\n",
        "print(\"  Building S1 test features...\")\n",
        "X_test_s1, _, meta_test_s1 = get_features(\n",
        "    split='test', scenario=1, mode='test',\n",
        "    data_config=data_config, features_config=features_config,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Build test features for Scenario 2  \n",
        "print(\"  Building S2 test features...\")\n",
        "X_test_s2, _, meta_test_s2 = get_features(\n",
        "    split='test', scenario=2, mode='test',\n",
        "    data_config=data_config, features_config=features_config,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Load trained models and make predictions\n",
        "print(\"  Loading models and predicting...\")\n",
        "\n",
        "# Scenario 1 predictions (average across folds)\n",
        "s1_preds_list = []\n",
        "s1_model_dir = RUN_DIR / 'models_s1'\n",
        "for fold_path in sorted(s1_model_dir.glob('fold_*')):\n",
        "    model_path = fold_path / 'model.cbm'  # CatBoost format\n",
        "    if model_path.exists():\n",
        "        model = ModelClass.load(str(model_path), s1_model_config)\n",
        "        preds = model.predict(X_test_s1)\n",
        "        s1_preds_list.append(preds)\n",
        "\n",
        "s1_test_preds = np.mean(s1_preds_list, axis=0) if s1_preds_list else np.ones(len(X_test_s1))\n",
        "\n",
        "# Scenario 2 predictions (average across folds)\n",
        "s2_preds_list = []\n",
        "s2_model_dir = RUN_DIR / 'models_s2'\n",
        "for fold_path in sorted(s2_model_dir.glob('fold_*')):\n",
        "    model_path = fold_path / 'model.cbm'\n",
        "    if model_path.exists():\n",
        "        model = ModelClass.load(str(model_path), s2_model_config)\n",
        "        preds = model.predict(X_test_s2)\n",
        "        s2_preds_list.append(preds)\n",
        "\n",
        "s2_test_preds = np.mean(s2_preds_list, axis=0) if s2_preds_list else np.ones(len(X_test_s2))\n",
        "\n",
        "print(f\"  S1 predictions: {len(s1_test_preds):,}\")\n",
        "print(f\"  S2 predictions: {len(s2_test_preds):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfb662d",
      "metadata": {
        "id": "2cfb662d"
      },
      "source": [
        "### 7.2 Create Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cb04ac",
      "metadata": {
        "id": "d6cb04ac"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.2 Create and Save Submission\n",
        "# ==============================================================================\n",
        "\n",
        "# Create submission dataframes\n",
        "submission_s1 = meta_test_s1[['country', 'brand_name', 'months_postgx']].copy()\n",
        "submission_s1['volume'] = s1_test_preds * meta_test_s1['avg_vol_12m'].values  # Convert y_norm to volume\n",
        "\n",
        "submission_s2 = meta_test_s2[['country', 'brand_name', 'months_postgx']].copy()\n",
        "submission_s2['volume'] = s2_test_preds * meta_test_s2['avg_vol_12m'].values\n",
        "\n",
        "# Combine submissions\n",
        "submission = pd.concat([submission_s1, submission_s2], ignore_index=True)\n",
        "\n",
        "# Clip negative volumes to 0\n",
        "submission['volume'] = submission['volume'].clip(lower=0)\n",
        "\n",
        "# Validate submission format\n",
        "is_valid, issues = validate_submission_format(submission)\n",
        "if is_valid:\n",
        "    print(\"‚úÖ Submission format validated\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Validation issues: {issues}\")\n",
        "\n",
        "# Save submission\n",
        "submission_path = Path(SUBMISSIONS_PATH) / f\"submission_{RUN_ID}.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"\\nüìÑ Submission saved to: {submission_path}\")\n",
        "print(f\"  Shape: {submission.shape}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "\n",
        "# Statistics\n",
        "print(f\"\\nüìä Submission Statistics:\")\n",
        "print(f\"  Volume min: {submission['volume'].min():.2f}\")\n",
        "print(f\"  Volume max: {submission['volume'].max():.2f}\")\n",
        "print(f\"  Volume mean: {submission['volume'].mean():.2f}\")\n",
        "print(f\"  Volume median: {submission['volume'].median():.2f}\")\n",
        "\n",
        "# Preview\n",
        "print(f\"\\nüìã Preview:\")\n",
        "display(submission.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6308c791",
      "metadata": {
        "id": "6308c791"
      },
      "source": [
        "## 10. Utilities & Helpers\n",
        "\n",
        "Useful utility functions for common operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfcc4c4",
      "metadata": {
        "id": "1cfcc4c4"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.3 Download Submission (Colab only)\n",
        "# ==============================================================================\n",
        "if IN_COLAB:\n",
        "    print(\"üì• Downloading submission file...\")\n",
        "    from google.colab import files\n",
        "    files.download(str(submission_path))\n",
        "    print(\"‚úÖ Download complete!\")\n",
        "else:\n",
        "    print(f\"üìÑ Submission available at: {submission_path}\")\n",
        "\n",
        "# Also sync to Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    # Copy to Drive submissions folder\n",
        "    import shutil\n",
        "    drive_submission_path = f\"{SUBMISSIONS_PATH}/submission_{RUN_ID}.csv\"\n",
        "    shutil.copy(str(submission_path), drive_submission_path)\n",
        "    print(f\"‚òÅÔ∏è Saved to Google Drive: {drive_submission_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8de5b70",
      "metadata": {},
      "source": [
        "## 8. Utilities\n",
        "\n",
        "Helper functions for common operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58871fc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 8.1 Utility Functions\n",
        "# ==============================================================================\n",
        "\n",
        "def show_memory():\n",
        "    \"\"\"Display current memory usage.\"\"\"\n",
        "    mem = get_memory_usage()\n",
        "    print(f\"üíæ Memory Usage:\")\n",
        "    print(f\"  Process: {mem.get('process_rss_gb', 'N/A'):.2f} GB\")\n",
        "    print(f\"  System: {mem.get('system_used_percent', 'N/A'):.1f}% used\")\n",
        "    if 'gpu_allocated_gb' in mem:\n",
        "        print(f\"  GPU: {mem['gpu_allocated_gb']:.2f} GB allocated\")\n",
        "\n",
        "def free_memory():\n",
        "    \"\"\"Free unused memory.\"\"\"\n",
        "    before = get_memory_usage().get('process_rss_gb', 0)\n",
        "    clear_memory()\n",
        "    after = get_memory_usage().get('process_rss_gb', 0)\n",
        "    print(f\"üßπ Freed {before - after:.2f} GB\")\n",
        "\n",
        "def download_artifacts():\n",
        "    \"\"\"Download all artifacts as a zip file (Colab only).\"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(f\"üìÅ Artifacts at: {RUN_DIR}\")\n",
        "        return\n",
        "    \n",
        "    import shutil\n",
        "    zip_path = f\"/content/artifacts_{RUN_ID}.zip\"\n",
        "    shutil.make_archive(zip_path.replace('.zip', ''), 'zip', str(RUN_DIR))\n",
        "    \n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "    print(f\"üì¶ Downloaded: artifacts_{RUN_ID}.zip\")\n",
        "\n",
        "def restart_runtime():\n",
        "    \"\"\"Restart Colab runtime to free memory.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        import os\n",
        "        os.kill(os.getpid(), 9)\n",
        "\n",
        "print(\"üõ†Ô∏è Utility functions available:\")\n",
        "print(\"  - show_memory(): Display memory usage\")\n",
        "print(\"  - free_memory(): Free unused memory\")\n",
        "print(\"  - download_artifacts(): Download all run artifacts\")\n",
        "print(\"  - restart_runtime(): Restart Colab runtime\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
