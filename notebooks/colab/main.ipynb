{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64988215",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armanfeili/novartis_datathon_2025/blob/Arman/notebooks/colab/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d532273",
      "metadata": {
        "id": "2d532273"
      },
      "source": [
        "# üß¨ Novartis Datathon 2025 - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a **complete end-to-end pipeline** for the Novartis Datathon 2025.\n",
        "\n",
        "## Configuration Structure\n",
        "\n",
        "Each model has **one consolidated config file** supporting all training modes:\n",
        "- `configs/model_xgb.yaml` - XGBoost (primary model)\n",
        "- `configs/model_lgbm.yaml` - LightGBM (secondary model)  \n",
        "- `configs/model_cat.yaml` - CatBoost (tertiary model)\n",
        "\n",
        "Each config includes: `model`, `sweep`, `scenario_best_params`, `validation`, `gpu`, `training`, `categorical_features`, `tuning`, `ensemble`\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Sections\n",
        "\n",
        "1. **üîß Environment Setup** - Mount Drive, clone repo, install dependencies\n",
        "2. **üìä Data Loading** - Load raw data and build panels\n",
        "3. **üî¨ Feature Engineering** - Build scenario-specific features  \n",
        "4. **üèãÔ∏è Model Training** - Train with GPU acceleration (multiple modes)\n",
        "5. **üîÑ Hyperparameter Sweep** - Grid search with K-fold CV, select by **official_metric**\n",
        "6. **ü§ù Ensemble** - XGBoost + LightGBM weighted ensemble\n",
        "7. **üì§ Submission** - Generate competition submission files\n",
        "\n",
        "---\n",
        "\n",
        "## Training Modes\n",
        "\n",
        "| Mode | Description | Use Case |\n",
        "|------|-------------|----------|\n",
        "| `quick` | Use best known params from `scenario_best_params` | Fast baseline |\n",
        "| `cv` | K-fold CV with best params | Robust single model |\n",
        "| `sweep` | Grid search with holdout | Find optimal params |\n",
        "| `sweep_cv` | Grid search with K-fold CV | Most robust tuning |\n",
        "| `ensemble` | XGB + LGBM weighted average | Best submission |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Principles\n",
        "- ‚úÖ **Selection by official_metric** (PE), not RMSE\n",
        "- ‚úÖ **K-fold CV** (3-5 folds) for robust hyperparameter selection\n",
        "- ‚úÖ **XGB+LGBM ensemble** with optimized weights\n",
        "- ‚úÖ **GPU acceleration** for all models on Colab\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7cb47e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7cb47e",
        "outputId": "19aa1c88-b017-42fa-b3f2-6e307d2ea8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted successfully\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.1 Detect Environment and Mount Google Drive\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect if running in Colab\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "print(f\"üñ•Ô∏è  Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted successfully\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - using local paths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd0aa8d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cd0aa8d",
        "outputId": "aad58a59-705d-4795-85cb-22bf0e22383f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Repository exists at /content/drive/MyDrive/novartis_datathon_2025. Pulling latest changes...\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10 (delta 6), reused 10 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (10/10), 8.06 KiB | 26.00 KiB/s, done.\n",
            "From https://github.com/armanfeili/novartis_datathon_2025\n",
            " * branch            Arman      -> FETCH_HEAD\n",
            "   67c14aa..5c33709  Arman      -> origin/Arman\n",
            "HEAD is now at 5c33709 project setup - 3\n",
            "/content/drive/MyDrive/novartis_datathon_2025\n",
            "\n",
            "üìÅ Project Path: /content/drive/MyDrive/novartis_datathon_2025\n",
            "üìÅ Data Path: /content/drive/MyDrive/novartis-datathon-2025/data\n",
            "üìÅ Artifacts Path: /content/drive/MyDrive/novartis-datathon-2025/artifacts\n",
            "üìÅ Submissions Path: /content/drive/MyDrive/novartis-datathon-2025/submissions\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.2 Clone Repository and Set Paths\n",
        "# ==============================================================================\n",
        "import os\n",
        "\n",
        "# --- Configuration (MODIFY THESE) ---\n",
        "REPO_URL = \"https://github.com/armanfeili/novartis_datathon_2025.git\"\n",
        "BRANCH = \"Arman\"  # Change to your working branch\n",
        "\n",
        "# Paths depend on environment\n",
        "if IN_COLAB:\n",
        "    DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "    PROJECT_PATH = \"/content/novartis_datathon_2025\"  # Clone to /content for speed\n",
        "    DATA_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/data\"  # Data on Drive\n",
        "    ARTIFACTS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/artifacts\"\n",
        "    SUBMISSIONS_PATH = f\"{DRIVE_BASE}/novartis-datathon-2025/submissions\"\n",
        "else:\n",
        "    # Local paths (relative to notebook location)\n",
        "    PROJECT_PATH = str(Path.cwd().parent.parent)\n",
        "    DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
        "    ARTIFACTS_PATH = os.path.join(PROJECT_PATH, \"artifacts\")\n",
        "    SUBMISSIONS_PATH = os.path.join(PROJECT_PATH, \"submissions\")\n",
        "# --------------------------------\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone or update repository\n",
        "    if not os.path.exists(PROJECT_PATH):\n",
        "        print(f\"üì• Cloning repository...\")\n",
        "        !git clone --branch {BRANCH} {REPO_URL} {PROJECT_PATH}\n",
        "    else:\n",
        "        print(f\"üìÇ Repository exists. Pulling latest changes...\")\n",
        "        %cd {PROJECT_PATH}\n",
        "        !git fetch origin {BRANCH}\n",
        "        !git reset --hard origin/{BRANCH}\n",
        "    \n",
        "    %cd {PROJECT_PATH}\n",
        "    \n",
        "    # Create symlinks to Drive data (if data is on Drive)\n",
        "    if os.path.exists(DATA_PATH):\n",
        "        local_data = os.path.join(PROJECT_PATH, \"data\")\n",
        "        if not os.path.exists(local_data):\n",
        "            !ln -s {DATA_PATH} {local_data}\n",
        "            print(f\"üîó Linked data directory from Drive\")\n",
        "\n",
        "# Create required directories\n",
        "for path in [DATA_PATH, ARTIFACTS_PATH, SUBMISSIONS_PATH]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# Print paths\n",
        "print(f\"\\nüìÅ Project: {PROJECT_PATH}\")\n",
        "print(f\"üìÅ Data: {DATA_PATH}\")\n",
        "print(f\"üìÅ Artifacts: {ARTIFACTS_PATH}\")\n",
        "print(f\"üìÅ Submissions: {SUBMISSIONS_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd7f350",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfd7f350",
        "outputId": "7ea6c438-55a0-40db-c862-e3d25e3f73c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  ‚úÖ torch\n",
            "  ‚úÖ numpy\n",
            "  ‚úÖ pandas\n",
            "  ‚úÖ lightgbm\n",
            "  ‚úÖ xgboost\n",
            "  ‚úÖ catboost\n",
            "  ‚úÖ sklearn\n",
            "  ‚úÖ yaml\n",
            "\n",
            "‚úÖ All dependencies installed!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1.3 Install Dependencies\n",
        "# ==============================================================================\n",
        "import subprocess\n",
        "\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "\n",
        "# Install from colab requirements\n",
        "!pip install -q -r env/colab_requirements.txt\n",
        "\n",
        "# For GPU support, ensure CUDA-compatible versions\n",
        "if IN_COLAB:\n",
        "    # XGBoost with GPU\n",
        "    !pip install -q xgboost --upgrade\n",
        "    \n",
        "    # LightGBM with GPU (requires OpenCL)\n",
        "    !pip install -q lightgbm --upgrade\n",
        "    \n",
        "    # CatBoost with GPU\n",
        "    !pip install -q catboost --upgrade\n",
        "\n",
        "# Verify key packages\n",
        "import importlib\n",
        "\n",
        "packages = [\n",
        "    ('numpy', 'numpy'),\n",
        "    ('pandas', 'pandas'),\n",
        "    ('sklearn', 'scikit-learn'),\n",
        "    ('yaml', 'pyyaml'),\n",
        "    ('tqdm', 'tqdm'),\n",
        "    ('catboost', 'catboost'),\n",
        "    ('lightgbm', 'lightgbm'),\n",
        "    ('xgboost', 'xgboost'),\n",
        "    ('pyarrow', 'pyarrow'),\n",
        "    ('scipy', 'scipy'),\n",
        "]\n",
        "\n",
        "print(\"\\nüìã Package Status:\")\n",
        "for import_name, pkg_name in packages:\n",
        "    try:\n",
        "        mod = importlib.import_module(import_name)\n",
        "        version = getattr(mod, '__version__', 'installed')\n",
        "        print(f\"  ‚úÖ {pkg_name}: {version}\")\n",
        "    except ImportError:\n",
        "        print(f\"  ‚ùå {pkg_name}: not installed\")\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"\\nüñ•Ô∏è GPU Status:\")\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  ‚úÖ CUDA available: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  ‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"  ‚ö†Ô∏è CUDA not available - using CPU\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Check via nvidia-smi\n",
        "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader 2>/dev/null || echo \"  ‚ÑπÔ∏è nvidia-smi not available\"\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a8cd44",
      "metadata": {
        "id": "00a8cd44"
      },
      "source": [
        "## 2. Import Modules and Verify Environment\n",
        "\n",
        "Import project modules and verify GPU availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63474d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63474d74",
        "outputId": "053ae606-25b3-4d85-cfc8-c460de74a61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üñ•Ô∏è  Device: cpu\n",
            "\n",
            "‚úÖ All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 2.1 Import Project Modules\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure project root is in path\n",
        "if PROJECT_PATH not in sys.path:\n",
        "    sys.path.insert(0, PROJECT_PATH)\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Project imports\n",
        "from src.utils import (\n",
        "    load_config, set_seed, setup_logging, timer, \n",
        "    get_device, get_gpu_info, print_environment_info,\n",
        "    clear_memory, get_memory_usage, optimize_dataframe_memory\n",
        ")\n",
        "from src.data import (\n",
        "    get_panel, load_raw_data, prepare_base_panel, \n",
        "    compute_pre_entry_stats, handle_missing_values,\n",
        "    META_COLS\n",
        ")\n",
        "from src.features import (\n",
        "    get_features, make_features, split_features_target_meta,\n",
        "    get_feature_columns, SCENARIO_CONFIG\n",
        ")\n",
        "from src.train import train_scenario_model, run_cross_validation\n",
        "from src.evaluate import compute_metric1, compute_metric2, compute_per_series_error\n",
        "from src.inference import (\n",
        "    generate_submission, detect_test_scenarios, \n",
        "    validate_submission_format, save_submission_with_versioning\n",
        ")\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2.2 Display Environment Information\n",
        "# ==============================================================================\n",
        "print_environment_info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "286fbdcc",
      "metadata": {
        "id": "286fbdcc"
      },
      "source": [
        "## 3. Load Configuration and Set Seed\n",
        "\n",
        "Load all configuration files and set random seed for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c891f807",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c891f807",
        "outputId": "7d082df9-35cd-4f14-ffbb-1bf4c86214de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configurations loaded:\n",
            "  - Data config: ['drive', 'local', 'files', 'keys', 'dates', 'columns', 'validation']\n",
            "  - Features config: ['feature_groups', 'lags', 'rolling', 'diff', 'time_features', 'interactions', 'selection', 'encoding']\n",
            "  - Run config: ['experiment', 'run', 'reproducibility', 'cv', 'paths', 'output', 'metrics', 'logging', 'drive', 'hardware']\n",
            "  - Model configs: ['lightgbm', 'xgboost', 'catboost', 'linear', 'neural_network']\n",
            "\n",
            "üé≤ Random seed: 42\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 3.1 Load Configurations\n",
        "# ==============================================================================\n",
        "data_config = load_config('configs/data.yaml')\n",
        "features_config = load_config('configs/features.yaml')\n",
        "run_config = load_config('configs/run_defaults.yaml')\n",
        "\n",
        "# Load all model configs (one file per model)\n",
        "model_configs = {\n",
        "    'xgboost': load_config('configs/model_xgb.yaml'),    # Primary model\n",
        "    'lightgbm': load_config('configs/model_lgbm.yaml'),  # Secondary model\n",
        "    'catboost': load_config('configs/model_cat.yaml'),   # Tertiary (ensemble diversity)\n",
        "}\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = run_config['reproducibility']['seed']\n",
        "set_seed(SEED)\n",
        "\n",
        "# Setup logging\n",
        "setup_logging(level=run_config.get('logging', {}).get('level', 'INFO'))\n",
        "\n",
        "print(\"üìã Configurations loaded:\")\n",
        "print(f\"  - Random seed: {SEED}\")\n",
        "print(f\"  - Scenarios: {list(run_config['scenarios'].keys())}\")\n",
        "\n",
        "# Display model priorities\n",
        "print(f\"\\nüèÜ Model Priorities (by official_metric):\")\n",
        "for name, cfg in model_configs.items():\n",
        "    priority = cfg.get('model', {}).get('priority', 99)\n",
        "    sweep_metric = cfg.get('sweep', {}).get('selection_metric', 'rmse')\n",
        "    print(f\"  {priority}. {name.upper()} - selection: {sweep_metric}\")\n",
        "\n",
        "# Display scenario details\n",
        "print(f\"\\nüìÖ Scenario Configuration:\")\n",
        "for s_name, s_config in run_config['scenarios'].items():\n",
        "    print(f\"  {s_name}:\")\n",
        "    print(f\"    Forecast: months {s_config['forecast_start']} to {s_config['forecast_end']}\")\n",
        "    print(f\"    Feature cutoff: month {s_config['feature_cutoff']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafc46c9",
      "metadata": {
        "id": "dafc46c9"
      },
      "source": [
        "## 4. Load and Explore Data\n",
        "\n",
        "Load the training and test data panels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4881a89e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4881a89e",
        "outputId": "c4ae155e-a98c-439f-ecda-788964482add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Data Directories:\n",
            "  Raw: /content/drive/MyDrive/novartis-datathon-2025/data/raw (exists: True)\n",
            "  Interim: /content/drive/MyDrive/novartis-datathon-2025/data/interim (exists: True)\n",
            "  Processed: /content/drive/MyDrive/novartis-datathon-2025/data/processed (exists: True)\n",
            "\n",
            "üìÑ Available raw files (0):\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.1 Load Training Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading training data...\")\n",
        "\n",
        "with timer(\"Load train panel\"):\n",
        "    train_panel = get_panel(split='train', config=data_config, use_cache=True)\n",
        "\n",
        "# Display statistics\n",
        "n_series = train_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "print(f\"\\nüìä Training Panel Statistics:\")\n",
        "print(f\"  Shape: {train_panel.shape[0]:,} rows √ó {train_panel.shape[1]} columns\")\n",
        "print(f\"  Unique series: {n_series:,}\")\n",
        "print(f\"  Time range: {train_panel['months_postgx'].min()} to {train_panel['months_postgx'].max()}\")\n",
        "\n",
        "# Bucket distribution\n",
        "bucket_dist = train_panel[['country', 'brand_name', 'bucket']].drop_duplicates()['bucket'].value_counts()\n",
        "print(f\"\\nü™£ Bucket Distribution:\")\n",
        "for bucket, count in bucket_dist.items():\n",
        "    pct = count / n_series * 100\n",
        "    print(f\"  Bucket {bucket}: {count:,} series ({pct:.1f}%)\")\n",
        "\n",
        "# Memory usage\n",
        "mem_mb = train_panel.memory_usage(deep=True).sum() / (1024**2)\n",
        "print(f\"\\nüíæ Memory: {mem_mb:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b9c8aac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "6b9c8aac",
        "outputId": "62bddad9-70b0-4010-ad25-55c5a9b7ef0a"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'items'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1657483188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Note: Update configs/data.yaml with your actual file names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üìä Loaded {len(raw_data)} datasets:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/novartis_datathon_2025/src/data.py\u001b[0m in \u001b[0;36mload_raw_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Load Raw Data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 4.2 Load Test Panel\n",
        "# ==============================================================================\n",
        "print(\"üìÇ Loading test data...\")\n",
        "\n",
        "with timer(\"Load test panel\"):\n",
        "    test_panel = get_panel(split='test', config=data_config, use_cache=True)\n",
        "\n",
        "# Detect scenarios\n",
        "test_scenarios = detect_test_scenarios(test_panel)\n",
        "n_test_series = test_panel[['country', 'brand_name']].drop_duplicates().shape[0]\n",
        "\n",
        "print(f\"\\nüìä Test Panel Statistics:\")\n",
        "print(f\"  Shape: {test_panel.shape[0]:,} rows √ó {test_panel.shape[1]} columns\")\n",
        "print(f\"  Unique series: {n_test_series:,}\")\n",
        "print(f\"  Scenario 1 series: {len(test_scenarios[1]):,}\")\n",
        "print(f\"  Scenario 2 series: {len(test_scenarios[2]):,}\")\n",
        "\n",
        "# Clear memory\n",
        "clear_memory()\n",
        "print(f\"\\nüßπ Memory cleared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98ae59ab",
      "metadata": {
        "id": "98ae59ab"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 4.3 Quick Data Exploration\n",
        "# ==============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. y_norm distribution\n",
        "ax = axes[0, 0]\n",
        "train_panel['y_norm'].hist(bins=50, ax=ax, color='steelblue', edgecolor='white')\n",
        "ax.axvline(x=1.0, color='red', linestyle='--', label='No erosion (1.0)')\n",
        "ax.axvline(x=0.25, color='orange', linestyle='--', label='Bucket 1 threshold')\n",
        "ax.set_xlabel('Normalized Volume (y_norm)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Distribution of y_norm')\n",
        "ax.legend()\n",
        "\n",
        "# 2. Mean erosion curve by bucket\n",
        "ax = axes[0, 1]\n",
        "for bucket in [1, 2]:\n",
        "    bucket_data = train_panel[train_panel['bucket'] == bucket]\n",
        "    erosion_by_month = bucket_data.groupby('months_postgx')['y_norm'].mean()\n",
        "    ax.plot(erosion_by_month.index, erosion_by_month.values, \n",
        "            label=f'Bucket {bucket}', linewidth=2)\n",
        "ax.axhline(y=1.0, color='gray', linestyle=':', alpha=0.7)\n",
        "ax.set_xlabel('Months Post Generic Entry')\n",
        "ax.set_ylabel('Mean Normalized Volume')\n",
        "ax.set_title('Erosion Curves by Bucket')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Number of generics over time\n",
        "ax = axes[1, 0]\n",
        "ngxs_by_month = train_panel.groupby('months_postgx')['n_gxs'].mean()\n",
        "ax.bar(ngxs_by_month.index, ngxs_by_month.values, color='forestgreen', alpha=0.7)\n",
        "ax.set_xlabel('Months Post Generic Entry')\n",
        "ax.set_ylabel('Mean Number of Generics')\n",
        "ax.set_title('Average Generic Competition Over Time')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 4. Hospital rate distribution\n",
        "ax = axes[1, 1]\n",
        "if 'hospital_rate' in train_panel.columns:\n",
        "    hr_by_series = train_panel.groupby(['country', 'brand_name'])['hospital_rate'].first()\n",
        "    hr_by_series.hist(bins=30, ax=ax, color='purple', edgecolor='white', alpha=0.7)\n",
        "    ax.set_xlabel('Hospital Rate (%)')\n",
        "    ax.set_ylabel('Number of Series')\n",
        "    ax.set_title('Hospital Rate Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Data exploration complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba3b589",
      "metadata": {
        "id": "eba3b589"
      },
      "source": [
        "## 5. Feature Engineering\n",
        "\n",
        "Build scenario-specific features for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96056c47",
      "metadata": {
        "id": "96056c47"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 5.1 Build Features for Both Scenarios\n",
        "# ==============================================================================\n",
        "\n",
        "# Build Scenario 1 features (forecast months 0-23 using pre-entry only)\n",
        "print(\"üî¨ Building Scenario 1 features...\")\n",
        "with timer(\"Scenario 1 features\"):\n",
        "    X_train_s1, y_train_s1, meta_train_s1 = get_features(\n",
        "        split='train', scenario=1, mode='train',\n",
        "        data_config=data_config, features_config=features_config,\n",
        "        use_cache=True\n",
        "    )\n",
        "print(f\"  X shape: {X_train_s1.shape}\")\n",
        "print(f\"  y shape: {y_train_s1.shape}\")\n",
        "print(f\"  Features: {len(X_train_s1.columns)}\")\n",
        "\n",
        "# Build Scenario 2 features (forecast months 6-23 using pre-entry + months 0-5)\n",
        "print(\"\\nüî¨ Building Scenario 2 features...\")\n",
        "with timer(\"Scenario 2 features\"):\n",
        "    X_train_s2, y_train_s2, meta_train_s2 = get_features(\n",
        "        split='train', scenario=2, mode='train',\n",
        "        data_config=data_config, features_config=features_config,\n",
        "        use_cache=True\n",
        "    )\n",
        "print(f\"  X shape: {X_train_s2.shape}\")\n",
        "print(f\"  y shape: {y_train_s2.shape}\")\n",
        "print(f\"  Features: {len(X_train_s2.columns)}\")\n",
        "\n",
        "# Display some feature examples\n",
        "print(f\"\\nüìã Sample Features (Scenario 1):\")\n",
        "print(f\"  {list(X_train_s1.columns[:10])}...\")\n",
        "\n",
        "# Check for early erosion features in S2 only\n",
        "s2_only_features = [c for c in X_train_s2.columns if 'erosion_0' in c or 'avg_vol_0' in c]\n",
        "if s2_only_features:\n",
        "    print(f\"\\nüìã Scenario 2 Specific Features:\")\n",
        "    print(f\"  {s2_only_features[:5]}...\")\n",
        "\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22178dd4",
      "metadata": {
        "id": "22178dd4"
      },
      "source": [
        "## 6. Model Training\n",
        "\n",
        "Train CatBoost models for both scenarios using cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22078bc1",
      "metadata": {
        "id": "22078bc1"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.1 Training Configuration\n",
        "# ==============================================================================\n",
        "\n",
        "# ============ CONFIGURE YOUR TRAINING HERE ============\n",
        "# Model options: 'xgboost', 'lightgbm', 'catboost'\n",
        "MODEL_TYPE = 'xgboost'  # Primary model (best performing)\n",
        "\n",
        "# Training mode options:\n",
        "# - 'quick'    : Use best known params (from config scenario_best_params)\n",
        "# - 'cv'       : Train with K-fold cross-validation using best params\n",
        "# - 'sweep'    : Run hyperparameter sweep with holdout validation\n",
        "# - 'sweep_cv' : Run sweep with K-fold cross-validation (most robust)\n",
        "# - 'ensemble' : Train XGBoost + LightGBM ensemble\n",
        "# - 'compare'  : Compare all models and select best by official_metric\n",
        "TRAINING_MODE = 'cv'\n",
        "\n",
        "N_FOLDS = 5  # Number of CV folds\n",
        "USE_GPU = True  # Enable GPU acceleration\n",
        "# =====================================================\n",
        "\n",
        "# Create run ID\n",
        "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_DIR = Path(ARTIFACTS_PATH) / RUN_ID\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"üèÉ Training Configuration:\")\n",
        "print(f\"  Run ID: {RUN_ID}\")\n",
        "print(f\"  Model: {MODEL_TYPE}\")\n",
        "print(f\"  Mode: {TRAINING_MODE}\")\n",
        "print(f\"  CV Folds: {N_FOLDS}\")\n",
        "print(f\"  Artifacts: {RUN_DIR}\")\n",
        "\n",
        "# Check GPU availability and configure\n",
        "gpu_info = get_gpu_info()\n",
        "GPU_AVAILABLE = gpu_info['gpu_available'] and gpu_info.get('cuda_version')\n",
        "\n",
        "if GPU_AVAILABLE and USE_GPU:\n",
        "    print(f\"  üöÄ GPU: {gpu_info.get('device_name', 'Available')} - GPU training enabled\")\n",
        "else:\n",
        "    print(f\"  üíª Using CPU training\")\n",
        "    USE_GPU = False\n",
        "\n",
        "# Set environment variable for thread safety (important for XGBoost/LightGBM)\n",
        "import os\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "\n",
        "# Show sweep configuration if using sweep mode\n",
        "if TRAINING_MODE in ['sweep', 'sweep_cv']:\n",
        "    sweep_config = model_configs[MODEL_TYPE].get('sweep', {})\n",
        "    print(f\"\\nüîç Sweep Configuration (from configs/model_{MODEL_TYPE.replace('boost', '')}.yaml):\")\n",
        "    print(f\"  Selection metric: {sweep_config.get('selection_metric', 'official_metric')}\")\n",
        "    axes = sweep_config.get('axes', {})\n",
        "    total_combos = 1\n",
        "    for param, values in axes.items():\n",
        "        print(f\"  - {param}: {values}\")\n",
        "        total_combos *= len(values)\n",
        "    print(f\"  Total combinations: {total_combos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417260a5",
      "metadata": {
        "id": "417260a5"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.2 Configure GPU-Enabled Model Parameters\n",
        "# ==============================================================================\n",
        "from src.models import get_model_class\n",
        "\n",
        "def get_gpu_model_config(model_type, base_config, use_gpu=True):\n",
        "    \"\"\"\n",
        "    Get model configuration with GPU settings enabled.\n",
        "    Uses gpu section from consolidated model config files.\n",
        "    \n",
        "    Args:\n",
        "        model_type: 'xgboost', 'lightgbm', or 'catboost'\n",
        "        base_config: Base model configuration dict\n",
        "        use_gpu: Whether to enable GPU\n",
        "        \n",
        "    Returns:\n",
        "        Updated model configuration\n",
        "    \"\"\"\n",
        "    config = base_config.copy()\n",
        "    params = config.get('model', {}).get('params', {}).copy()\n",
        "    gpu_config = config.get('gpu', {})\n",
        "    \n",
        "    if use_gpu and GPU_AVAILABLE:\n",
        "        # Apply GPU settings from config\n",
        "        if model_type == 'xgboost':\n",
        "            params['tree_method'] = gpu_config.get('tree_method', 'gpu_hist')\n",
        "            params['gpu_id'] = gpu_config.get('gpu_id', 0)\n",
        "            params['predictor'] = gpu_config.get('predictor', 'gpu_predictor')\n",
        "            print(\"  üöÄ XGBoost GPU mode enabled (tree_method='gpu_hist')\")\n",
        "            \n",
        "        elif model_type == 'lightgbm':\n",
        "            params['device'] = 'gpu'\n",
        "            params['gpu_platform_id'] = gpu_config.get('gpu_platform_id', 0)\n",
        "            params['gpu_device_id'] = gpu_config.get('gpu_device_id', 0)\n",
        "            print(\"  ‚ö° LightGBM GPU mode enabled (device='gpu')\")\n",
        "            \n",
        "        elif model_type == 'catboost':\n",
        "            params['task_type'] = 'GPU'\n",
        "            params['devices'] = str(gpu_config.get('device_id', 0))\n",
        "            print(\"  üê± CatBoost GPU mode enabled (task_type='GPU')\")\n",
        "    else:\n",
        "        # Use CPU settings from config\n",
        "        if model_type == 'xgboost':\n",
        "            params['tree_method'] = config.get('model', {}).get('params', {}).get('tree_method', 'hist')\n",
        "        elif model_type == 'lightgbm':\n",
        "            params['device'] = 'cpu'\n",
        "        elif model_type == 'catboost':\n",
        "            params['task_type'] = 'CPU'\n",
        "        print(f\"  üíª {model_type} CPU mode\")\n",
        "    \n",
        "    # Update config with modified params\n",
        "    config_copy = config.copy()\n",
        "    if 'model' in config_copy:\n",
        "        config_copy['model'] = config_copy['model'].copy()\n",
        "        config_copy['model']['params'] = params\n",
        "    else:\n",
        "        config_copy['params'] = params\n",
        "    \n",
        "    return config_copy\n",
        "\n",
        "# Get GPU-enabled config for selected model\n",
        "print(f\"\\nüîß Configuring {MODEL_TYPE}...\")\n",
        "current_model_config = get_gpu_model_config(MODEL_TYPE, model_configs[MODEL_TYPE], USE_GPU)\n",
        "\n",
        "# Get model class\n",
        "ModelClass = get_model_class(MODEL_TYPE)\n",
        "print(f\"  Model class: {ModelClass.__name__}\")\n",
        "\n",
        "# Display selected params\n",
        "selected_params = current_model_config.get('model', current_model_config).get('params', {})\n",
        "print(f\"\\nüìã Model Parameters:\")\n",
        "for k, v in list(selected_params.items())[:8]:\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddfd0994",
      "metadata": {
        "id": "ddfd0994"
      },
      "source": [
        "### 6.3 Train Scenario 1 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b7bf71",
      "metadata": {
        "id": "d6b7bf71"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.3 Train Scenario 1 Model\n",
        "# ==============================================================================\n",
        "print(f\"üèãÔ∏è Training Scenario 1 - {MODEL_TYPE.upper()}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train with cross-validation\n",
        "s1_cv_results = run_cross_validation(\n",
        "    X=X_train_s1,\n",
        "    y=y_train_s1,\n",
        "    meta_df=meta_train_s1,\n",
        "    scenario=1,\n",
        "    model_config=current_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_dir=RUN_DIR / 'models_s1',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 1 Training Complete\")\n",
        "print(f\"  Mean CV Metric: {s1_cv_results['mean_score']:.6f} ¬± {s1_cv_results['std_score']:.6f}\")\n",
        "\n",
        "# Save S1 OOF predictions\n",
        "oof_s1 = pd.DataFrame({\n",
        "    'y_true': y_train_s1,\n",
        "    'y_pred': s1_cv_results['oof_predictions'],\n",
        "})\n",
        "oof_s1.to_csv(RUN_DIR / 'oof_s1.csv', index=False)\n",
        "\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b361db6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.4 Train Scenario 2 Model\n",
        "# ==============================================================================\n",
        "print(f\"üèãÔ∏è Training Scenario 2 - {MODEL_TYPE.upper()}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Train with cross-validation\n",
        "s2_cv_results = run_cross_validation(\n",
        "    X=X_train_s2,\n",
        "    y=y_train_s2,\n",
        "    meta_df=meta_train_s2,\n",
        "    scenario=2,\n",
        "    model_config=current_model_config,\n",
        "    run_config=run_config,\n",
        "    n_folds=N_FOLDS,\n",
        "    save_dir=RUN_DIR / 'models_s2',\n",
        "    run_id=RUN_ID,\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Scenario 2 Training Complete\")\n",
        "print(f\"  Mean CV Metric: {s2_cv_results['mean_score']:.6f} ¬± {s2_cv_results['std_score']:.6f}\")\n",
        "\n",
        "# Save S2 OOF predictions\n",
        "oof_s2 = pd.DataFrame({\n",
        "    'y_true': y_train_s2,\n",
        "    'y_pred': s2_cv_results['oof_predictions'],\n",
        "})\n",
        "oof_s2.to_csv(RUN_DIR / 'oof_s2.csv', index=False)\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üìä TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"  Model: {MODEL_TYPE.upper()}\")\n",
        "print(f\"  GPU: {'Enabled' if USE_GPU and GPU_AVAILABLE else 'Disabled'}\")\n",
        "print(f\"  Scenario 1 CV: {s1_cv_results['mean_score']:.6f} ¬± {s1_cv_results['std_score']:.6f}\")\n",
        "print(f\"  Scenario 2 CV: {s2_cv_results['mean_score']:.6f} ¬± {s2_cv_results['std_score']:.6f}\")\n",
        "print(f\"  Models saved to: {RUN_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912dfd34",
      "metadata": {},
      "source": [
        "## 6.5 Advanced Training Options\n",
        "\n",
        "The cells below provide advanced training options:\n",
        "- **Hyperparameter Sweep**: Grid search with K-fold CV to find optimal parameters\n",
        "- **Multi-Model Training**: Train all models (XGBoost, LightGBM, CatBoost)\n",
        "- **Ensemble**: Combine XGBoost + LightGBM predictions for better performance\n",
        "\n",
        "‚ö†Ô∏è These are optional and computationally intensive. Skip to Section 7 for basic submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4b9b11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5a Train All Models (XGBoost, LightGBM, CatBoost)\n",
        "# ==============================================================================\n",
        "# Set RUN_ALL_MODELS = True to train all three models and compare\n",
        "\n",
        "RUN_ALL_MODELS = False  # ‚ö†Ô∏è Set to True to run (takes ~15-30 min with GPU)\n",
        "\n",
        "if RUN_ALL_MODELS:\n",
        "    all_model_results = {}\n",
        "    \n",
        "    for model_name in ['xgboost', 'lightgbm', 'catboost']:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"üèãÔ∏è Training {model_name.upper()}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Get GPU-enabled config\n",
        "        model_cfg = get_gpu_model_config(model_name, model_configs[model_name], USE_GPU)\n",
        "        \n",
        "        # Train S1\n",
        "        s1_results = run_cross_validation(\n",
        "            X=X_train_s1, y=y_train_s1, meta_df=meta_train_s1,\n",
        "            scenario=1, model_config=model_cfg, run_config=run_config,\n",
        "            n_folds=N_FOLDS, save_dir=RUN_DIR / f'{model_name}_s1', run_id=RUN_ID\n",
        "        )\n",
        "        \n",
        "        # Train S2\n",
        "        s2_results = run_cross_validation(\n",
        "            X=X_train_s2, y=y_train_s2, meta_df=meta_train_s2,\n",
        "            scenario=2, model_config=model_cfg, run_config=run_config,\n",
        "            n_folds=N_FOLDS, save_dir=RUN_DIR / f'{model_name}_s2', run_id=RUN_ID\n",
        "        )\n",
        "        \n",
        "        all_model_results[model_name] = {\n",
        "            's1_mean': s1_results['mean_score'],\n",
        "            's1_std': s1_results['std_score'],\n",
        "            's2_mean': s2_results['mean_score'],\n",
        "            's2_std': s2_results['std_score'],\n",
        "            's1_oof': s1_results['oof_predictions'],\n",
        "            's2_oof': s2_results['oof_predictions'],\n",
        "        }\n",
        "        \n",
        "        print(f\"  S1: {s1_results['mean_score']:.4f} ¬± {s1_results['std_score']:.4f}\")\n",
        "        print(f\"  S2: {s2_results['mean_score']:.4f} ¬± {s2_results['std_score']:.4f}\")\n",
        "        \n",
        "        clear_memory()\n",
        "    \n",
        "    # Display comparison table\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä MODEL COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "    comparison_df = pd.DataFrame([\n",
        "        {\n",
        "            'Model': name.upper(),\n",
        "            'S1 Mean': f\"{r['s1_mean']:.4f}\",\n",
        "            'S1 Std': f\"¬±{r['s1_std']:.4f}\",\n",
        "            'S2 Mean': f\"{r['s2_mean']:.4f}\",\n",
        "            'S2 Std': f\"¬±{r['s2_std']:.4f}\",\n",
        "        }\n",
        "        for name, r in all_model_results.items()\n",
        "    ])\n",
        "    display(comparison_df)\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_ALL_MODELS = True to train all models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f3fe3c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5b Hyperparameter Sweep with K-Fold CV (using consolidated configs)\n",
        "# ==============================================================================\n",
        "# Run a grid search over hyperparameters with cross-validation\n",
        "# Sweep parameters are defined in configs/model_xgb.yaml and configs/model_lgbm.yaml\n",
        "\n",
        "RUN_SWEEP = False  # ‚ö†Ô∏è Set to True to run (takes ~30-60 min)\n",
        "\n",
        "if RUN_SWEEP:\n",
        "    from src.train import run_sweep_with_cv\n",
        "    \n",
        "    # Select model for sweep (use consolidated config files)\n",
        "    SWEEP_MODEL = 'xgboost'  # 'xgboost' or 'lightgbm'\n",
        "    SWEEP_FOLDS = 3  # Fewer folds for faster sweep\n",
        "    \n",
        "    # Get sweep configuration from consolidated model config\n",
        "    sweep_model_config = model_configs[SWEEP_MODEL]\n",
        "    sweep_axes = sweep_model_config.get('sweep', {}).get('axes', {})\n",
        "    selection_metric = sweep_model_config.get('sweep', {}).get('selection_metric', 'official_metric')\n",
        "    \n",
        "    print(f\"üîç Running {SWEEP_MODEL.upper()} hyperparameter sweep...\")\n",
        "    print(f\"  Config file: configs/model_{SWEEP_MODEL.replace('boost', '')}.yaml\")\n",
        "    print(f\"  Selection metric: {selection_metric}\")\n",
        "    print(f\"  Folds: {SWEEP_FOLDS}\")\n",
        "    print(f\"  GPU: {'Enabled' if USE_GPU else 'Disabled'}\")\n",
        "    print(f\"\\n  Sweep axes:\")\n",
        "    \n",
        "    total_combos = 1\n",
        "    for param, values in sweep_axes.items():\n",
        "        print(f\"    {param}: {values}\")\n",
        "        total_combos *= len(values)\n",
        "    print(f\"  Total combinations: {total_combos}\")\n",
        "    \n",
        "    # Config file path for sweep\n",
        "    config_path = f'configs/model_xgb.yaml' if SWEEP_MODEL == 'xgboost' else f'configs/model_lgbm.yaml'\n",
        "    \n",
        "    # Run sweep for both scenarios\n",
        "    sweep_all_results = {}\n",
        "    for scenario in [1, 2]:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Scenario {scenario} Sweep\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        sweep_results = run_sweep_with_cv(\n",
        "            scenario=scenario,\n",
        "            model_type=SWEEP_MODEL,\n",
        "            model_config_path=config_path,\n",
        "            run_config_path='configs/run_defaults.yaml',\n",
        "            data_config_path='configs/data.yaml',\n",
        "            features_config_path='configs/features.yaml',\n",
        "            base_run_name=f\"{RUN_ID}_{SWEEP_MODEL}_s{scenario}\",\n",
        "            n_folds=SWEEP_FOLDS,\n",
        "            use_cached_features=True\n",
        "        )\n",
        "        \n",
        "        sweep_all_results[scenario] = sweep_results\n",
        "        \n",
        "        print(f\"\\n‚úÖ Best config: {sweep_results['best_config']}\")\n",
        "        print(f\"   Mean {selection_metric}: {sweep_results['best_mean_metric']:.4f} ¬± {sweep_results['best_std_metric']:.4f}\")\n",
        "        \n",
        "        # Display results table\n",
        "        if 'summary_df' in sweep_results:\n",
        "            display(sweep_results['summary_df'])\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"üìä SWEEP SUMMARY ({SWEEP_MODEL.upper()})\")\n",
        "    print(\"=\"*60)\n",
        "    for s in [1, 2]:\n",
        "        r = sweep_all_results[s]\n",
        "        print(f\"  Scenario {s}: {r['best_mean_metric']:.4f}\")\n",
        "        print(f\"    Best params: {r['best_config']}\")\n",
        "    \n",
        "    clear_memory()\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_SWEEP = True to run hyperparameter sweep\")\n",
        "    print(\"   Sweep configuration is in configs/model_xgb.yaml and configs/model_lgbm.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e12de8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 6.5c XGBoost + LightGBM Ensemble (using consolidated configs)\n",
        "# ==============================================================================\n",
        "# Train both XGBoost and LightGBM and combine predictions\n",
        "# Ensemble settings are defined in configs/model_xgb.yaml and configs/model_lgbm.yaml\n",
        "\n",
        "RUN_ENSEMBLE = False  # ‚ö†Ô∏è Set to True to run (takes ~10-20 min)\n",
        "\n",
        "if RUN_ENSEMBLE:\n",
        "    from src.train import train_xgb_lgbm_ensemble\n",
        "    \n",
        "    print(\"ü§ù Training XGBoost + LightGBM Ensemble...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Get ensemble settings from configs\n",
        "    xgb_ensemble_cfg = model_configs['xgboost'].get('ensemble', {})\n",
        "    lgbm_ensemble_cfg = model_configs['lightgbm'].get('ensemble', {})\n",
        "    \n",
        "    # Determine weight optimization method\n",
        "    optimize_weights = xgb_ensemble_cfg.get('optimize_weights', True)\n",
        "    weight_search = xgb_ensemble_cfg.get('weight_search', 'grid')\n",
        "    \n",
        "    print(f\"  XGBoost weight range: {xgb_ensemble_cfg.get('weight_range', [0.4, 0.8])}\")\n",
        "    print(f\"  LightGBM weight range: {lgbm_ensemble_cfg.get('weight_range', [0.2, 0.6])}\")\n",
        "    print(f\"  Optimize weights: {optimize_weights}\")\n",
        "    print(f\"  Search method: {weight_search}\")\n",
        "    \n",
        "    # Get GPU configs for both models\n",
        "    xgb_cfg = get_gpu_model_config('xgboost', model_configs['xgboost'], USE_GPU)\n",
        "    lgbm_cfg = get_gpu_model_config('lightgbm', model_configs['lightgbm'], USE_GPU)\n",
        "    \n",
        "    ensemble_results = {}\n",
        "    \n",
        "    for scenario in [1, 2]:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Scenario {scenario} Ensemble\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Select data\n",
        "        if scenario == 1:\n",
        "            X_train, y_train, meta_train = X_train_s1, y_train_s1, meta_train_s1\n",
        "        else:\n",
        "            X_train, y_train, meta_train = X_train_s2, y_train_s2, meta_train_s2\n",
        "        \n",
        "        result = train_xgb_lgbm_ensemble(\n",
        "            X_train=X_train,\n",
        "            y_train=y_train,\n",
        "            meta_train=meta_train,\n",
        "            scenario=scenario,\n",
        "            xgb_config=xgb_cfg,\n",
        "            lgbm_config=lgbm_cfg,\n",
        "            run_config=run_config,\n",
        "            n_folds=N_FOLDS,\n",
        "            optimize_weights=optimize_weights,\n",
        "            save_dir=RUN_DIR / f'ensemble_s{scenario}'\n",
        "        )\n",
        "        \n",
        "        ensemble_results[scenario] = result\n",
        "        \n",
        "        print(f\"\\n‚úÖ Scenario {scenario} Ensemble Results:\")\n",
        "        print(f\"   XGBoost:  {result['xgb_metric']:.4f}\")\n",
        "        print(f\"   LightGBM: {result['lgbm_metric']:.4f}\")\n",
        "        print(f\"   Ensemble: {result['ensemble_metric']:.4f}\")\n",
        "        print(f\"   Weights:  XGB={result['weights'][0]:.2f}, LGBM={result['weights'][1]:.2f}\")\n",
        "        \n",
        "        clear_memory()\n",
        "    \n",
        "    # Save ensemble configuration for inference\n",
        "    import json\n",
        "    ensemble_output = {\n",
        "        's1_weights': list(ensemble_results[1]['weights']),\n",
        "        's2_weights': list(ensemble_results[2]['weights']),\n",
        "        's1_xgb_metric': ensemble_results[1]['xgb_metric'],\n",
        "        's1_lgbm_metric': ensemble_results[1]['lgbm_metric'],\n",
        "        's1_ensemble_metric': ensemble_results[1]['ensemble_metric'],\n",
        "        's2_xgb_metric': ensemble_results[2]['xgb_metric'],\n",
        "        's2_lgbm_metric': ensemble_results[2]['lgbm_metric'],\n",
        "        's2_ensemble_metric': ensemble_results[2]['ensemble_metric'],\n",
        "    }\n",
        "    with open(RUN_DIR / 'ensemble_config.json', 'w') as f:\n",
        "        json.dump(ensemble_output, f, indent=2)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä ENSEMBLE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    for s in [1, 2]:\n",
        "        r = ensemble_results[s]\n",
        "        improvement_over_xgb = r['ensemble_metric'] - r['xgb_metric']\n",
        "        print(f\"  Scenario {s}: {r['ensemble_metric']:.4f}\")\n",
        "        print(f\"    XGB: {r['xgb_metric']:.4f}, LGBM: {r['lgbm_metric']:.4f}\")\n",
        "        print(f\"    Weights: XGB={r['weights'][0]:.0%}, LGBM={r['weights'][1]:.0%}\")\n",
        "        print(f\"    Improvement over XGB alone: {improvement_over_xgb:+.4f}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Set RUN_ENSEMBLE = True to train XGBoost + LightGBM ensemble\")\n",
        "    print(\"   Ensemble settings are in configs/model_xgb.yaml and configs/model_lgbm.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548b8c8e",
      "metadata": {
        "id": "548b8c8e"
      },
      "source": [
        "## 7. Generate Submission\n",
        "\n",
        "Generate predictions on test data and create submission files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09beced8",
      "metadata": {
        "id": "09beced8"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.1 Build Test Features and Generate Predictions\n",
        "# ==============================================================================\n",
        "import joblib\n",
        "from glob import glob\n",
        "\n",
        "print(\"üì§ Generating submission...\")\n",
        "\n",
        "# Build test features for Scenario 1\n",
        "print(\"  Building S1 test features...\")\n",
        "X_test_s1, _, meta_test_s1 = get_features(\n",
        "    split='test', scenario=1, mode='test',\n",
        "    data_config=data_config, features_config=features_config,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Build test features for Scenario 2  \n",
        "print(\"  Building S2 test features...\")\n",
        "X_test_s2, _, meta_test_s2 = get_features(\n",
        "    split='test', scenario=2, mode='test',\n",
        "    data_config=data_config, features_config=features_config,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "# Determine model file extension based on model type\n",
        "MODEL_EXTENSIONS = {\n",
        "    'catboost': 'model.cbm',\n",
        "    'xgboost': 'model.json',\n",
        "    'lightgbm': 'model.txt',\n",
        "}\n",
        "model_ext = MODEL_EXTENSIONS.get(MODEL_TYPE, 'model.bin')\n",
        "\n",
        "print(f\"  Loading {MODEL_TYPE.upper()} models and predicting...\")\n",
        "\n",
        "# Scenario 1 predictions (average across folds)\n",
        "s1_preds_list = []\n",
        "s1_model_dir = RUN_DIR / 'models_s1'\n",
        "for fold_path in sorted(s1_model_dir.glob('fold_*')):\n",
        "    model_files = list(fold_path.glob('model.*'))\n",
        "    if model_files:\n",
        "        model_path = model_files[0]\n",
        "        model = ModelClass.load(str(model_path), current_model_config)\n",
        "        preds = model.predict(X_test_s1)\n",
        "        s1_preds_list.append(preds)\n",
        "        print(f\"    Loaded {model_path.name} from fold_{fold_path.name.split('_')[-1]}\")\n",
        "\n",
        "if s1_preds_list:\n",
        "    s1_test_preds = np.mean(s1_preds_list, axis=0)\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è No S1 models found, using baseline predictions\")\n",
        "    s1_test_preds = np.ones(len(X_test_s1))\n",
        "\n",
        "# Scenario 2 predictions (average across folds)\n",
        "s2_preds_list = []\n",
        "s2_model_dir = RUN_DIR / 'models_s2'\n",
        "for fold_path in sorted(s2_model_dir.glob('fold_*')):\n",
        "    model_files = list(fold_path.glob('model.*'))\n",
        "    if model_files:\n",
        "        model_path = model_files[0]\n",
        "        model = ModelClass.load(str(model_path), current_model_config)\n",
        "        preds = model.predict(X_test_s2)\n",
        "        s2_preds_list.append(preds)\n",
        "        print(f\"    Loaded {model_path.name} from fold_{fold_path.name.split('_')[-1]}\")\n",
        "\n",
        "if s2_preds_list:\n",
        "    s2_test_preds = np.mean(s2_preds_list, axis=0)\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è No S2 models found, using baseline predictions\")\n",
        "    s2_test_preds = np.ones(len(X_test_s2))\n",
        "\n",
        "print(f\"\\n  S1 predictions: {len(s1_test_preds):,}\")\n",
        "print(f\"  S2 predictions: {len(s2_test_preds):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cfb662d",
      "metadata": {
        "id": "2cfb662d"
      },
      "source": [
        "### 7.2 Create Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6cb04ac",
      "metadata": {
        "id": "d6cb04ac"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.2 Create and Save Submission\n",
        "# ==============================================================================\n",
        "\n",
        "# Create submission dataframes\n",
        "submission_s1 = meta_test_s1[['country', 'brand_name', 'months_postgx']].copy()\n",
        "submission_s1['volume'] = s1_test_preds * meta_test_s1['avg_vol_12m'].values  # Convert y_norm to volume\n",
        "\n",
        "submission_s2 = meta_test_s2[['country', 'brand_name', 'months_postgx']].copy()\n",
        "submission_s2['volume'] = s2_test_preds * meta_test_s2['avg_vol_12m'].values\n",
        "\n",
        "# Combine submissions\n",
        "submission = pd.concat([submission_s1, submission_s2], ignore_index=True)\n",
        "\n",
        "# Clip negative volumes to 0\n",
        "submission['volume'] = submission['volume'].clip(lower=0)\n",
        "\n",
        "# Validate submission format\n",
        "is_valid, issues = validate_submission_format(submission)\n",
        "if is_valid:\n",
        "    print(\"‚úÖ Submission format validated\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Validation issues: {issues}\")\n",
        "\n",
        "# Save submission\n",
        "submission_path = Path(SUBMISSIONS_PATH) / f\"submission_{RUN_ID}.csv\"\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"\\nüìÑ Submission saved to: {submission_path}\")\n",
        "print(f\"  Shape: {submission.shape}\")\n",
        "print(f\"  Columns: {list(submission.columns)}\")\n",
        "\n",
        "# Statistics\n",
        "print(f\"\\nüìä Submission Statistics:\")\n",
        "print(f\"  Volume min: {submission['volume'].min():.2f}\")\n",
        "print(f\"  Volume max: {submission['volume'].max():.2f}\")\n",
        "print(f\"  Volume mean: {submission['volume'].mean():.2f}\")\n",
        "print(f\"  Volume median: {submission['volume'].median():.2f}\")\n",
        "\n",
        "# Preview\n",
        "print(f\"\\nüìã Preview:\")\n",
        "display(submission.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfcc4c4",
      "metadata": {
        "id": "1cfcc4c4"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 7.3 Download Submission (Colab only)\n",
        "# ==============================================================================\n",
        "if IN_COLAB:\n",
        "    print(\"üì• Downloading submission file...\")\n",
        "    from google.colab import files\n",
        "    files.download(str(submission_path))\n",
        "    print(\"‚úÖ Download complete!\")\n",
        "else:\n",
        "    print(f\"üìÑ Submission available at: {submission_path}\")\n",
        "\n",
        "# Also sync to Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    # Copy to Drive submissions folder\n",
        "    import shutil\n",
        "    drive_submission_path = f\"{SUBMISSIONS_PATH}/submission_{RUN_ID}.csv\"\n",
        "    shutil.copy(str(submission_path), drive_submission_path)\n",
        "    print(f\"‚òÅÔ∏è Saved to Google Drive: {drive_submission_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8de5b70",
      "metadata": {},
      "source": [
        "## 8. Utilities\n",
        "\n",
        "Helper functions for common operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58871fc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# 8.1 Utility Functions\n",
        "# ==============================================================================\n",
        "\n",
        "def show_memory():\n",
        "    \"\"\"Display current memory usage.\"\"\"\n",
        "    mem = get_memory_usage()\n",
        "    print(f\"üíæ Memory Usage:\")\n",
        "    print(f\"  Process: {mem.get('process_rss_gb', 'N/A'):.2f} GB\")\n",
        "    print(f\"  System: {mem.get('system_used_percent', 'N/A'):.1f}% used\")\n",
        "    if 'gpu_allocated_gb' in mem:\n",
        "        print(f\"  GPU: {mem['gpu_allocated_gb']:.2f} GB allocated\")\n",
        "\n",
        "def free_memory():\n",
        "    \"\"\"Free unused memory.\"\"\"\n",
        "    before = get_memory_usage().get('process_rss_gb', 0)\n",
        "    clear_memory()\n",
        "    after = get_memory_usage().get('process_rss_gb', 0)\n",
        "    print(f\"üßπ Freed {before - after:.2f} GB\")\n",
        "\n",
        "def download_artifacts():\n",
        "    \"\"\"Download all artifacts as a zip file (Colab only).\"\"\"\n",
        "    if not IN_COLAB:\n",
        "        print(f\"üìÅ Artifacts at: {RUN_DIR}\")\n",
        "        return\n",
        "    \n",
        "    import shutil\n",
        "    zip_path = f\"/content/artifacts_{RUN_ID}.zip\"\n",
        "    shutil.make_archive(zip_path.replace('.zip', ''), 'zip', str(RUN_DIR))\n",
        "    \n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "    print(f\"üì¶ Downloaded: artifacts_{RUN_ID}.zip\")\n",
        "\n",
        "def restart_runtime():\n",
        "    \"\"\"Restart Colab runtime to free memory.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        import os\n",
        "        os.kill(os.getpid(), 9)\n",
        "\n",
        "def check_gpu():\n",
        "    \"\"\"Check GPU status and memory.\"\"\"\n",
        "    print(\"üñ•Ô∏è GPU Status:\")\n",
        "    !nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu --format=csv,noheader 2>/dev/null || print(\"  GPU not available\")\n",
        "\n",
        "print(\"üõ†Ô∏è Utility functions available:\")\n",
        "print(\"  - show_memory(): Display memory usage\")\n",
        "print(\"  - free_memory(): Free unused memory\")\n",
        "print(\"  - check_gpu(): Check GPU status and memory\")\n",
        "print(\"  - download_artifacts(): Download all run artifacts\")\n",
        "print(\"  - restart_runtime(): Restart Colab runtime\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
